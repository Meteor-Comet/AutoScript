#http://localhost:8501/
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime
import tempfile
import shutil

# å¯¼å…¥æ™ºèƒ½åˆ—è¯†åˆ«å‡½æ•°
from smart_column_functions import find_header_row, identify_key_columns, identify_columns_by_pattern, is_phone_number

def smart_column_detection(df, filename):
    """
    æ™ºèƒ½è¯†åˆ«è¡¨æ ¼ä¸­çš„å§“åã€è”ç³»æ–¹å¼ã€æ”¶è´§åœ°å€ç­‰ä¿¡æ¯ï¼Œä¸ä¾èµ–å›ºå®šçš„åˆ—åå’Œè¡Œå·
    """
    try:
        # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°çœŸæ­£çš„è¡¨å¤´è¡Œ
        header_row_idx = find_header_row(df)
        
        # å¦‚æœæ‰¾åˆ°äº†è¡¨å¤´è¡Œï¼Œé‡æ–°è®¾ç½®åˆ—å
        if header_row_idx is not None and header_row_idx > 0:
            # ä¿å­˜åŸå§‹åˆ—åä»¥å¤‡åç”¨
            original_columns = df.columns.tolist()
            # è®¾ç½®æ–°çš„åˆ—å
            df.columns = df.iloc[header_row_idx].values
            # åªä¿ç•™è¡¨å¤´è¡Œä¹‹åçš„æ•°æ®
            df = df.iloc[header_row_idx+1:].reset_index(drop=True)
        
        # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½åŒ¹é…å…³é”®åˆ—
        column_mapping = identify_key_columns(df)
        
        # ç¬¬ä¸‰æ­¥ï¼šæå–æ•°æ®
        extracted_data = []
        
        for index, row in df.iterrows():
            try:
                # åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é¡¹
                item = {
                    'å®¢æˆ·åç§°': '',
                    'æ”¶è´§åœ°å€': '',
                    'æ”¶è´§äºº': '',
                    'æ‰‹æœº': '',
                    'å®¢æˆ·å¤‡æ³¨': '',  # æ–°å¢å®¢æˆ·å¤‡æ³¨å­—æ®µ
                    'æºæ–‡ä»¶': filename
                }
                
                # æ ¹æ®è¯†åˆ«çš„åˆ—æ˜ å°„å¡«å……æ•°æ®
                for target_field, source_columns in column_mapping.items():
                    for col in source_columns:
                        if col in df.columns and pd.notna(row[col]) and str(row[col]).strip():
                            item[target_field] = str(row[col]).strip()
                            break
                
                # å°†å®¢æˆ·åç§°ï¼ˆåº—åï¼‰ç§»åŠ¨åˆ°å®¢æˆ·å¤‡æ³¨å­—æ®µ
                if item['å®¢æˆ·åç§°']:
                    item['å®¢æˆ·å¤‡æ³¨'] = item['å®¢æˆ·åç§°']
                    item['å®¢æˆ·åç§°'] = ''  # æ¸…ç©ºå®¢æˆ·åç§°å­—æ®µ
                
                # åªæœ‰å½“è‡³å°‘æœ‰æ”¶è´§äººæˆ–ç”µè¯ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ æ•°æ®
                if item['æ”¶è´§äºº'] or item['æ‰‹æœº']:
                    extracted_data.append(item)
                    
            except Exception as e:
                st.warning(f"å¤„ç†ç¬¬ {index+1} è¡Œæ—¶å‡ºé”™: {e}")
        
        return extracted_data
        
    except Exception as e:
        st.error(f"æ™ºèƒ½å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
        return []

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†ç³»ç»Ÿ",
    page_icon="ğŸ§®",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("æ•°æ®å¤„ç†ç³»ç»Ÿ")
st.markdown("---")

# ä¾§è¾¹æ 
st.sidebar.header("æ“ä½œé€‰é¡¹")
app_mode = st.sidebar.selectbox(
    "é€‰æ‹©åŠŸèƒ½",
    ["æ‰¹é‡å¤„ç†å‘æ”¾æ˜ç»†", "æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•", "æ ‡è®°å‘è´§æ˜ç»†é›†é‡‡ä¿¡æ¯", "å¯¼å…¥ç›´é‚®æ˜ç»†åˆ°ä¸‰æ‹©å¯¼å•", "å¢å¼ºç‰ˆVLOOKUP", "ç‰©æµå•å·åŒ¹é…", "è¡¨åˆå¹¶", "ä¾›åº”å•†è®¢å•åˆ†æ", "å•†å“åç§°æ ‡å‡†åŒ–", "å•†å“æ•°é‡è½¬æ¢"]
)

def process_å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶(file_path):
    """
    å¤„ç†å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶ï¼Œæå–æ€¡äºšé€šå…¬å¸çš„æ•°æ®
    """
    try:
        # è¯»å–Excelæ–‡ä»¶ï¼Œä¸æŒ‡å®šheaderä»¥ä¾¿æ‰‹åŠ¨å¤„ç†
        df = pd.read_excel(file_path, header=None)
        
        if df.empty:
            return pd.DataFrame()
        
        # è·å–æ ‡é¢˜è¡Œï¼ˆç¬¬ä¸€è¡Œæ˜¯æ–‡ä»¶åè¯´æ˜ï¼Œç¬¬äºŒè¡Œå¼€å§‹æ˜¯å®é™…æ ‡é¢˜ï¼‰
        header_row2 = df.iloc[1]  # ç¬¬äºŒè¡Œï¼ˆäº§å“åç§°ï¼‰
        header_row3 = df.iloc[2]  # ç¬¬ä¸‰è¡Œï¼ˆå…¬å¸åç§°ï¼‰
        
        # æ‰¾åˆ°åŒ…å«"æ€¡äºšé€š"çš„åˆ—
        yiyatong_cols = []
        for i in range(len(header_row3)):
            if pd.notna(header_row3[i]) and 'æ€¡äºšé€š' in str(header_row3[i]):
                product_name = header_row2[i] if pd.notna(header_row2[i]) else ""
                yiyatong_cols.append((i, product_name))
        
        if not yiyatong_cols:
            return pd.DataFrame()
        
        # æå–å‰14åˆ—çš„é€šç”¨ä¿¡æ¯
        info_columns = list(range(14))
        
        # æ„å»ºç»“æœæ•°æ®
        result_data = []
        
        # ä»ç¬¬4è¡Œå¼€å§‹æ˜¯æ•°æ®è¡Œï¼ˆç´¢å¼•3ï¼‰
        for row_idx in range(3, len(df)):
            row = df.iloc[row_idx]
            
            # è·³è¿‡åˆè®¡è¡Œ
            if pd.notna(row.iloc[0]) and 'åˆè®¡' in str(row.iloc[0]):
                continue
            
            # ä¸ºæ¯ä¸ªæ€¡äºšé€šäº§å“åˆ›å»ºä¸€è¡Œ
            for col_idx, product_name in yiyatong_cols:
                # æ£€æŸ¥è¯¥åˆ—çš„æ•°é‡æ˜¯å¦ä¸ä¸º0
                if col_idx < len(row) and pd.notna(row.iloc[col_idx]) and row.iloc[col_idx] != 0:
                    quantity = row.iloc[col_idx]
                    # åªæœ‰æ•°é‡ä¸ä¸º0çš„æ•°æ®æ‰æ·»åŠ 
                    if quantity != 0:
                        # è·å–é€šç”¨ä¿¡æ¯
                        base_info = []
                        for col_idx_info in info_columns:
                            if col_idx_info < len(row):
                                base_info.append(row.iloc[col_idx_info])
                            else:
                                base_info.append(None)
                        
                        # åˆ›å»ºä¸€è¡Œæ•°æ®ï¼šé€šç”¨ä¿¡æ¯(14åˆ—) + äº§å“åç§° + æ•°é‡
                        new_row = base_info + [product_name, quantity]
                        result_data.append(new_row)
        
        # æ›´æ–°åˆ—å®šä¹‰
        columns = ['åˆ¶å•æ—¥æœŸ', 'æ‰“å°æ—¶é—´', 'é¢†ç”¨å•å·', 'é¢†ç”¨ç±»å‹', 'æ–¹æ¡ˆç±»å‹', 'é¢†ç”¨éƒ¨é—¨', 
                  'åŒºåŸŸ', 'æ–¹æ¡ˆææŠ¥äºº', 'æ–¹æ¡ˆææŠ¥äººç”µè¯', 'å‘è´§ä»“åº“', 'æ”¶è´§äºº', 
                  'æ”¶è´§äººç”µè¯', 'æ”¶è´§åœ°å€', 'é¢†ç”¨è¯´æ˜', 'äº§å“åç§°', 'æ•°é‡']
        
        result_df = pd.DataFrame(result_data, columns=columns)
        return result_df
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

def save_with_formatting(df, filename):
    """
    ä¿å­˜DataFrameåˆ°Excelæ–‡ä»¶
    """
    df.to_excel(filename, index=False)

def batch_process_files(uploaded_files):
    """
    æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    """
    if not uploaded_files:
        st.warning("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        return None
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•æ¥ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    with tempfile.TemporaryDirectory() as temp_dir:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        file_paths = []
        for uploaded_file in uploaded_files:
            file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            file_paths.append(file_path)
        
        # å¤„ç†æ‰€æœ‰æ–‡ä»¶
        processed_data = []
        progress_bar = st.progress(0)
        total_files = len(file_paths)
        
        for i, file_path in enumerate(file_paths):
            progress_bar.progress((i + 1) / total_files)
            with st.spinner(f"æ­£åœ¨å¤„ç† {os.path.basename(file_path)}..."):
                df = process_å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶(file_path)
                if not df.empty:
                    processed_data.append(df)
                    st.success(f"æˆåŠŸå¤„ç† {os.path.basename(file_path)}ï¼Œæå–åˆ° {len(df)} è¡Œæ•°æ®")
        
        progress_bar.empty()
        
        # åˆå¹¶æ‰€æœ‰å¤„ç†è¿‡çš„æ•°æ®
        if processed_data:
            all_å‘æ”¾æ˜ç»† = pd.concat(processed_data, ignore_index=True)
            
            # æŒ‰åˆ¶å•æ—¥æœŸæ’åº
            if not all_å‘æ”¾æ˜ç»†.empty and 'åˆ¶å•æ—¥æœŸ' in all_å‘æ”¾æ˜ç»†.columns:
                all_å‘æ”¾æ˜ç»† = all_å‘æ”¾æ˜ç»†.sort_values('åˆ¶å•æ—¥æœŸ').reset_index(drop=True)
            
            # åªä¿ç•™å‰104è¡Œæ­£ç¡®çš„æ•°æ®
            if len(all_å‘æ”¾æ˜ç»†) > 104:
                all_å‘æ”¾æ˜ç»† = all_å‘æ”¾æ˜ç»†.iloc[:104]
            
            return all_å‘æ”¾æ˜ç»†
        else:
            st.warning("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ•°æ®")
            return None

def process_supplier_order_file(file_path):
    """
    å¤„ç†å•ä¸ªä¾›åº”å•†è®¢å•æŸ¥è¯¢æ–‡ä»¶
    """
    try:
        # è¯»å–Excelæ–‡ä»¶ï¼Œä¸æŒ‡å®šheaderä»¥ä¾¿æ‰‹åŠ¨å¤„ç†
        df = pd.read_excel(file_path, header=None)
        
        if df.empty:
            return None
            
        # è·å–æ ‡é¢˜è¡Œï¼ˆç¬¬äºŒè¡Œæ˜¯å®é™…çš„åˆ—æ ‡é¢˜ï¼‰
        header_row = df.iloc[1]
        
        # é‡å‘½ååˆ—
        expected_columns = ['è®¢å•ç¼–å·', 'ç¬¬ä¸‰æ–¹è®¢å•ç¼–å·', 'è®¢å•çŠ¶æ€', 'è®¢å•åˆ›å»ºæ—¶é—´', 'æ–¹æ¡ˆç¼–å·', 
                          'æ”¶è´§äºº', 'è”ç³»æ–¹å¼', 'çœä»½', 'åœ°å¸‚', 'åŒºå¿', 'æ”¶è´§åœ°å€', 
                          'å•†å“åç§°', 'æ•°é‡', 'å•ä»·(å…ƒ)', 'å•ä½', 'å«ç¨æ€»é‡‘é¢(å…ƒ)', 
                          'ä¾›åº”å•†', 'ä¸€ä»¶ä»£å‘', 'æ“ä½œ']
        
        # è·å–æ•°æ®ï¼ˆä»ç¬¬ä¸‰è¡Œå¼€å§‹ï¼‰
        data_df = df.iloc[2:].reset_index(drop=True)
        data_df.columns = expected_columns[:len(data_df.columns)]
        
        return data_df
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return None

def compare_data(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df):
    """
    æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•æ•°æ®
    åªæ ¸å¯¹ä¾›åº”å•†è®¢å•ä¸­å­˜åœ¨çš„è®°å½•ï¼ˆä»¥ä¾›åº”å•†è®¢å•ä¸ºå‡†ï¼‰
    åˆ†åˆ«æ ‡è¯†æ•°é‡ä¸ä¸€è‡´å’Œæ²¡æ‰¾åˆ°å¯¹åº”è®°å½•çš„æƒ…å†µ
    """
    try:
        # ç­›é€‰ä¾›åº”å•†ä¸ºæ€¡äºšé€šçš„è®¢å•
        yiyatong_orders = ä¾›åº”å•†è®¢å•_df[ä¾›åº”å•†è®¢å•_df['ä¾›åº”å•†'].str.contains('æ€¡äºšé€š', na=False)].copy()
        
        # é‡å‘½åä¾›åº”å•†è®¢å•åˆ—ä»¥ä¾¿åç»­å¤„ç†
        order_summary = yiyatong_orders[['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°', 'æ•°é‡']].copy()
        order_summary.rename(columns={'æ•°é‡': 'è®¢å•æ•°é‡'}, inplace=True)
        
        # é‡å‘½åå‘è´§æ˜ç»†åˆ—ä»¥ä¾¿åç»­å¤„ç†
        delivery_summary = å‘è´§æ˜ç»†_df[['é¢†ç”¨è¯´æ˜', 'æ”¶è´§äºº', 'äº§å“åç§°', 'æ•°é‡']].copy()
        delivery_summary.rename(columns={
            'é¢†ç”¨è¯´æ˜': 'æ–¹æ¡ˆç¼–å·',
            'äº§å“åç§°': 'å•†å“åç§°',
            'æ•°é‡': 'å‘è´§æ•°é‡'
        }, inplace=True)
        
        # æŒ‰æ–¹æ¡ˆç¼–å·ã€æ”¶è´§äººã€å•†å“åç§°åˆ†ç»„æ±‡æ€»æ•°é‡
        order_grouped = order_summary.groupby(['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°'])['è®¢å•æ•°é‡'].sum().reset_index()
        delivery_grouped = delivery_summary.groupby(['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°'])['å‘è´§æ•°é‡'].sum().reset_index()
        
        # ä»¥ä¾›åº”å•†è®¢å•ä¸ºå‡†è¿›è¡Œæ ¸å¯¹
        # å·¦è¿æ¥ç¡®ä¿æ‰€æœ‰ä¾›åº”å•†è®¢å•è®°å½•éƒ½è¢«åŒ…å«
        merged_data = pd.merge(order_grouped, delivery_grouped, on=['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°'], how='left')
        
        # å¡«å……NaNå€¼ï¼ˆå‘è´§æ˜ç»†ä¸­æ²¡æœ‰å¯¹åº”è®°å½•çš„æƒ…å†µï¼‰
        merged_data['å‘è´§æ•°é‡'] = merged_data['å‘è´§æ•°é‡'].fillna(0)
        
        # è®¡ç®—å·®å¼‚
        merged_data['æ•°é‡å·®å¼‚'] = merged_data['è®¢å•æ•°é‡'] - merged_data['å‘è´§æ•°é‡']
        
        # åˆ¤æ–­æ˜¯å¦ä¸€è‡´
        merged_data['æ˜¯å¦ä¸€è‡´'] = merged_data['æ•°é‡å·®å¼‚'] == 0
        
        # åˆ†ç±»ç»“æœ
        consistent_records = merged_data[merged_data['æ˜¯å¦ä¸€è‡´']].copy()
        
        # ä¸ä¸€è‡´çš„è®°å½•åˆ†ä¸ºä¸¤ç§æƒ…å†µ
        inconsistent_records = merged_data[(~merged_data['æ˜¯å¦ä¸€è‡´']) & (merged_data['å‘è´§æ•°é‡'] > 0)].copy()  # æ•°é‡ä¸ä¸€è‡´
        not_found_records = merged_data[merged_data['å‘è´§æ•°é‡'] == 0].copy()  # å‘è´§æ˜ç»†ä¸­æ²¡æ‰¾åˆ°
        
        # æ·»åŠ è¯´æ˜åˆ—
        consistent_records['æ ¸å¯¹ç»“æœ'] = 'æ•°é‡ä¸€è‡´'
        inconsistent_records['æ ¸å¯¹ç»“æœ'] = 'æ•°é‡ä¸ä¸€è‡´'
        not_found_records['æ ¸å¯¹ç»“æœ'] = 'å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°'
        
        return consistent_records, inconsistent_records, not_found_records, pd.DataFrame()
        
    except Exception as e:
        st.error(f"æ•°æ®æ ¸å¯¹æ—¶å‡ºé”™: {e}")
        st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        # è¿”å›ç©ºçš„DataFrame
        empty_df = pd.DataFrame()
        return empty_df, empty_df, empty_df, empty_df

def mark_procurement_info(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df):
    """
    æ ¹æ®ä¾›åº”å•†è®¢å•ä¸­çš„'ä¸€ä»¶ä»£å‘'å­—æ®µæ ‡è®°å‘è´§æ˜ç»†çš„'æ˜¯å¦é›†é‡‡'åˆ—
    """
    try:
        # ç­›é€‰ä¾›åº”å•†ä¸ºæ€¡äºšé€šçš„è®¢å•
        yiyatong_orders = ä¾›åº”å•†è®¢å•_df[ä¾›åº”å•†è®¢å•_df['ä¾›åº”å•†'].str.contains('æ€¡äºšé€š', na=False)].copy()
        
        # æ ¹æ®'ä¸€ä»¶ä»£å‘'åˆ—åˆ¤æ–­æ˜¯å¦é›†é‡‡ï¼ˆä¸€ä»¶ä»£å‘ä¸º'æ˜¯'è¡¨ç¤ºéé›†é‡‡ï¼‰
        yiyatong_orders['æ˜¯å¦é›†é‡‡'] = yiyatong_orders['ä¸€ä»¶ä»£å‘'].apply(
            lambda x: 'éé›†é‡‡' if str(x).strip() == 'æ˜¯' else 'é›†é‡‡'
        )
        
        # æŒ‰æ–¹æ¡ˆç¼–å·ã€æ”¶è´§äººã€è”ç³»æ–¹å¼å’Œå•†å“åç§°åˆ†ç»„ï¼Œç¡®å®šæ¯ä¸ªç»„åˆçš„é›†é‡‡çŠ¶æ€
        # å¦‚æœä»»ä½•ä¸€ä¸ªè®¢å•æ˜¯é›†é‡‡ï¼Œåˆ™æ•´ä¸ªç»„åˆä¸ºé›†é‡‡
        procurement_status = yiyatong_orders.groupby(['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'è”ç³»æ–¹å¼', 'å•†å“åç§°'])['æ˜¯å¦é›†é‡‡'].apply(
            lambda x: 'é›†é‡‡' if 'é›†é‡‡' in x.values else 'éé›†é‡‡'
        ).reset_index()
        
        # åˆ›å»ºä¸€ä¸ªç”¨äºåŒ¹é…çš„å‘è´§æ˜ç»†å‰¯æœ¬
        å‘è´§æ˜ç»†_marked = å‘è´§æ˜ç»†_df.copy()
        
        # åˆå§‹åŒ–'æ˜¯å¦é›†é‡‡'åˆ—ä¸ºç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯None
        å‘è´§æ˜ç»†_marked['æ˜¯å¦é›†é‡‡'] = ''
        
        # æ ¹æ®åŒ¹é…æ¡ä»¶æ›´æ–°'æ˜¯å¦é›†é‡‡'åˆ—
        for _, row in procurement_status.iterrows():
            mask = (
                (å‘è´§æ˜ç»†_marked['é¢†ç”¨è¯´æ˜'] == row['æ–¹æ¡ˆç¼–å·']) &
                (å‘è´§æ˜ç»†_marked['æ”¶è´§äºº'] == row['æ”¶è´§äºº']) &
                (å‘è´§æ˜ç»†_marked['æ”¶è´§äººç”µè¯'] == row['è”ç³»æ–¹å¼']) &
                (å‘è´§æ˜ç»†_marked['äº§å“åç§°'] == row['å•†å“åç§°'])
            )
            å‘è´§æ˜ç»†_marked.loc[mask, 'æ˜¯å¦é›†é‡‡'] = row['æ˜¯å¦é›†é‡‡']
        
        return å‘è´§æ˜ç»†_marked
        
    except Exception as e:
        st.error(f"æ ‡è®°é›†é‡‡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return å‘è´§æ˜ç»†_df

def extract_direct_mail_info(df, filename):
    """
    æ™ºèƒ½è¯†åˆ«ç›´é‚®è¡¨ä¸­çš„å…³é”®åˆ—å¹¶æå–æ•°æ®
    è¯†åˆ«è§„åˆ™ï¼š
    - æ‰‹æœºå·ï¼šåŒ…å«7-11ä½æ•°å­—çš„åˆ—
    - æ”¶è´§äººï¼šå¤§éƒ¨åˆ†æ˜¯2-4ä¸ªæ±‰å­—çš„åˆ—
    - åœ°å€ï¼šåŒ…å«è¾ƒé•¿æ–‡æœ¬çš„åˆ—
    - åº—åï¼šå•†æˆ·/åº—é“ºåç§°åˆ—
    """
    try:
        # 1. è¯†åˆ«å…³é”®åˆ—
        phone_col = None
        name_col = None
        address_col = None
        shop_col = None
        
        # åˆ†æå„åˆ—æ•°æ®ç‰¹å¾
        for col in df.columns:
            col_data = df[col].dropna().astype(str)
            if len(col_data) == 0:
                continue
                
            # è¯†åˆ«æ‰‹æœºå·åˆ—ï¼ˆåŒ…å«7-11ä½æ•°å­—ï¼‰
            if not phone_col:
                digit_counts = col_data.str.replace(r'\D', '', regex=True).str.len()
                if (digit_counts >= 7).mean() > 0.8:  # 80%ä»¥ä¸Šæ˜¯7ä½ä»¥ä¸Šæ•°å­—
                    phone_col = col
                    continue
                    
            # è¯†åˆ«æ”¶è´§äººåˆ—ï¼ˆå¤§éƒ¨åˆ†æ˜¯2-4ä¸ªæ±‰å­—ï¼‰
            if not name_col:
                name_lengths = col_data.str.len()
                chinese_chars = col_data.str.count(r'[\u4e00-\u9fa5]')
                if ((name_lengths >= 2) & (name_lengths <= 4)).mean() > 0.7 and (chinese_chars == name_lengths).mean() > 0.7:
                    name_col = col
                    continue
                    
            # è¯†åˆ«åœ°å€åˆ—ï¼ˆè¾ƒé•¿æ–‡æœ¬ï¼‰
            if not address_col:
                if (col_data.str.len() > 10).mean() > 0.7:
                    address_col = col
                    continue
                    
            # è¯†åˆ«åº—ååˆ—ï¼ˆéäººåã€éåœ°å€çš„æ–‡æœ¬ï¼‰
            if not shop_col:
                if (col_data.str.len() > 2).mean() > 0.7 and (col_data != df.get(phone_col, '')).all() and (col_data != df.get(name_col, '')).all():
                    shop_col = col
        
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
        st.write(f"è¯†åˆ«ç»“æœ: æ‰‹æœºâ†’{phone_col}, æ”¶è´§äººâ†’{name_col}, åœ°å€â†’{address_col}, åº—åâ†’{shop_col}")
        
        # 2. æå–æ•°æ®ï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œï¼‰
        extracted_data = []
        for index, row in df.iloc[1:].iterrows():
            item = {
                'æ”¶è´§äºº': str(row.get(name_col, '')).strip() if name_col else '',
                'æ‰‹æœº': str(row.get(phone_col, '')).strip() if phone_col else '',
                'æ”¶è´§åœ°å€': str(row.get(address_col, '')).strip() if address_col else '',
                'å®¢æˆ·å¤‡æ³¨': str(row.get(shop_col, '')).strip() if shop_col else '',
                'æºæ–‡ä»¶': filename
            }
            
            # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
            if not item['æ”¶è´§äºº'] and not item['æ‰‹æœº']:
                continue
                
            # ç¡®ä¿æ‰‹æœºå·åªåŒ…å«æ•°å­—
            if item['æ‰‹æœº']:
                item['æ‰‹æœº'] = ''.join(c for c in item['æ‰‹æœº'] if c.isdigit())[:11]
                
            extracted_data.append(item)
        
        # æ˜¾ç¤ºæå–ç»“æœç¤ºä¾‹
        if extracted_data:
            st.write("æå–æ•°æ®ç¤ºä¾‹:")
            st.dataframe(pd.DataFrame(extracted_data[:3]))
        
        return extracted_data
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return []

if app_mode == "æ‰¹é‡å¤„ç†å‘æ”¾æ˜ç»†":
    st.header("æ‰¹é‡å¤„ç†å‘æ”¾æ˜ç»†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
        type=["xlsx"],
        accept_multiple_files=True
    )

    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶å
        file_names = [f.name for f in uploaded_files]
        st.write("ä¸Šä¼ çš„æ–‡ä»¶:")
        st.write(file_names)
        
        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹å¤„ç†"):
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
                result_df = batch_process_files(uploaded_files)
                
                if result_df is not None and not result_df.empty:
                    st.success(f"å¤„ç†å®Œæˆï¼å…±æ±‡æ€» {len(result_df)} è¡Œæ•°æ®")
                    
                    # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                    st.subheader("å¤„ç†ç»“æœé¢„è§ˆ")
                    st.dataframe(result_df.head(20))
                    
                    # æä¾›ä¸‹è½½
                    output_file = f"å‘è´§æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    save_with_formatting(result_df, output_file)
                    
                    with open(output_file, "rb") as file:
                        st.download_button(
                            label="ä¸‹è½½å¤„ç†ç»“æœ",
                            data=file,
                            file_name=output_file,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                else:
                    st.error("å¤„ç†å¤±è´¥æˆ–æ²¡æœ‰æ•°æ®")

elif app_mode == "æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•":
    st.header("æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•")
    st.info("æ­¤åŠŸèƒ½ç”¨äºæ ¸å¯¹ä¾›åº”å•†è®¢å•ä¸­æ€¡äºšé€šçš„æ•°æ®ä¸å‘è´§æ˜ç»†æ˜¯å¦ä¸€è‡´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        delivery_file = st.file_uploader(
            "ä¸Šä¼ å‘è´§æ˜ç»†æ–‡ä»¶",
            type=["xlsx"],
            key="delivery_file"
        )
    
    with col2:
        order_files = st.file_uploader(
            "ä¸Šä¼ ä¾›åº”å•†è®¢å•æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰",
            type=["xlsx"],
            accept_multiple_files=True,
            key="order_files"
        )
    
    if delivery_file and order_files:
        if st.button("å¼€å§‹æ ¸å¯¹"):
            with st.spinner("æ­£åœ¨æ ¸å¯¹æ•°æ®..."):
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                with tempfile.TemporaryDirectory() as temp_dir:
                    # ä¿å­˜å‘è´§æ˜ç»†æ–‡ä»¶
                    delivery_path = os.path.join(temp_dir, delivery_file.name)
                    with open(delivery_path, "wb") as f:
                        f.write(delivery_file.getbuffer())
                    
                    # è¯»å–å‘è´§æ˜ç»†
                    try:
                        å‘è´§æ˜ç»†_df = pd.read_excel(delivery_path)
                        st.info(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶ï¼Œå…± {len(å‘è´§æ˜ç»†_df)} è¡Œæ•°æ®")
                    except Exception as e:
                        st.error(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                        st.stop()
                    
                    # ä¿å­˜ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    order_file_paths = []
                    for uploaded_file in order_files:
                        file_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        order_file_paths.append(file_path)
                    
                    # å¤„ç†æ‰€æœ‰ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    all_orders = []
                    for file_path in order_file_paths:
                        with st.spinner(f"æ­£åœ¨å¤„ç† {os.path.basename(file_path)}..."):
                            df = process_supplier_order_file(file_path)
                            if df is not None:
                                all_orders.append(df)
                                st.success(f"æˆåŠŸå¤„ç† {os.path.basename(file_path)}")
                    
                    if all_orders:
                        # åˆå¹¶æ‰€æœ‰è®¢å•æ•°æ®
                        ä¾›åº”å•†è®¢å•_df = pd.concat(all_orders, ignore_index=True)
                        st.info(f"åˆå¹¶è®¢å•æ•°æ®ï¼Œå…± {len(ä¾›åº”å•†è®¢å•_df)} è¡Œ")
                        
                        # è¿›è¡Œæ•°æ®æ ¸å¯¹
                        consistent_records, inconsistent_records, not_found_records, _ = compare_data(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df)
                        
                        # æ˜¾ç¤ºæ ¸å¯¹ç»“æœ
                        st.success("æ•°æ®æ ¸å¯¹å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºä¸€è‡´çš„è®°å½•
                        if not consistent_records.empty:
                            st.subheader("æ•°é‡ä¸€è‡´çš„è®°å½•")
                            st.dataframe(consistent_records)
                            st.success(f"å‘ç° {len(consistent_records)} æ¡æ•°é‡ä¸€è‡´çš„è®°å½•")
                        
                        # æ˜¾ç¤ºæ•°é‡ä¸ä¸€è‡´çš„è®°å½•
                        if not inconsistent_records.empty:
                            st.subheader("æ•°é‡ä¸ä¸€è‡´çš„è®°å½•")
                            st.dataframe(inconsistent_records)
                            st.warning(f"å‘ç° {len(inconsistent_records)} æ¡æ•°é‡ä¸ä¸€è‡´çš„è®°å½•")
                        
                        # æ˜¾ç¤ºå‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°çš„è®°å½•
                        if not not_found_records.empty:
                            st.subheader("å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°çš„è®°å½•")
                            st.dataframe(not_found_records)
                            st.error(f"å‘ç° {len(not_found_records)} æ¡å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°çš„è®°å½•")
                        
                        # ç»Ÿè®¡ä¿¡æ¯
                        total_records = len(consistent_records) + len(inconsistent_records) + len(not_found_records)
                        consistent_count = len(consistent_records)
                        st.info(f"æ€»å…±æ ¸å¯¹ {total_records} æ¡ä¾›åº”å•†è®¢å•è®°å½•")
                        st.info(f"  - æ•°é‡ä¸€è‡´: {consistent_count} æ¡")
                        st.info(f"  - æ•°é‡ä¸ä¸€è‡´: {len(inconsistent_records)} æ¡")
                        st.info(f"  - å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°: {len(not_found_records)} æ¡")
                        
                        # æä¾›ä¸‹è½½
                        output_file = f"æ ¸å¯¹ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                        # åˆå¹¶ç»“æœ
                        combined_result = pd.concat([consistent_records, inconsistent_records, not_found_records], ignore_index=True)
                        save_with_formatting(combined_result, output_file)
                        
                        with open(output_file, "rb") as file:
                            st.download_button(
                                label="ä¸‹è½½æ ¸å¯¹ç»“æœ",
                                data=file,
                                file_name=output_file,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                    else:
                        st.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ä¾›åº”å•†è®¢å•æ–‡ä»¶")

elif app_mode == "æ ‡è®°å‘è´§æ˜ç»†é›†é‡‡ä¿¡æ¯":
    st.header("æ ‡è®°å‘è´§æ˜ç»†é›†é‡‡ä¿¡æ¯")
    st.info("æ­¤åŠŸèƒ½æ ¹æ®ä¾›åº”å•†è®¢å•ä¸­çš„'ä¸€ä»¶ä»£å‘'å­—æ®µæ ‡è®°å‘è´§æ˜ç»†çš„'æ˜¯å¦é›†é‡‡'åˆ—")
    
    col1, col2 = st.columns(2)
    
    with col1:
        delivery_file = st.file_uploader(
            "ä¸Šä¼ å‘è´§æ˜ç»†æ–‡ä»¶",
            type=["xlsx"],
            key="delivery_file_procurement"
        )
    
    with col2:
        order_files = st.file_uploader(
            "ä¸Šä¼ ä¾›åº”å•†è®¢å•æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰",
            type=["xlsx"],
            accept_multiple_files=True,
            key="order_files_procurement"
        )
    
    if delivery_file and order_files:
        if st.button("å¼€å§‹æ ‡è®°"):
            with st.spinner("æ­£åœ¨æ ‡è®°é›†é‡‡ä¿¡æ¯..."):
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                with tempfile.TemporaryDirectory() as temp_dir:
                    # ä¿å­˜å‘è´§æ˜ç»†æ–‡ä»¶
                    delivery_path = os.path.join(temp_dir, delivery_file.name)
                    with open(delivery_path, "wb") as f:
                        f.write(delivery_file.getbuffer())
                    
                    # è¯»å–å‘è´§æ˜ç»†
                    try:
                        å‘è´§æ˜ç»†_df = pd.read_excel(delivery_path)
                        st.info(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶ï¼Œå…± {len(å‘è´§æ˜ç»†_df)} è¡Œæ•°æ®")
                    except Exception as e:
                        st.error(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                        st.stop()
                    
                    # ä¿å­˜ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    order_file_paths = []
                    for uploaded_file in order_files:
                        file_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        order_file_paths.append(file_path)
                    
                    # å¤„ç†æ‰€æœ‰ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    all_orders = []
                    for file_path in order_file_paths:
                        with st.spinner(f"æ­£åœ¨å¤„ç† {os.path.basename(file_path)}..."):
                            df = process_supplier_order_file(file_path)
                            if df is not None:
                                all_orders.append(df)
                                st.success(f"æˆåŠŸå¤„ç† {os.path.basename(file_path)}")
                    
                    if all_orders:
                        # åˆå¹¶æ‰€æœ‰è®¢å•æ•°æ®
                        ä¾›åº”å•†è®¢å•_df = pd.concat(all_orders, ignore_index=True)
                        st.info(f"åˆå¹¶è®¢å•æ•°æ®ï¼Œå…± {len(ä¾›åº”å•†è®¢å•_df)} è¡Œ")
                        
                        # æ ‡è®°é›†é‡‡ä¿¡æ¯
                        marked_df = mark_procurement_info(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df)
                        
                        if marked_df is not None:
                            st.success("é›†é‡‡ä¿¡æ¯æ ‡è®°å®Œæˆï¼")
                            
                            # æ˜¾ç¤ºæ ‡è®°ç»“æœç»Ÿè®¡ï¼ˆåŒ…å«ç©ºç™½çš„è¯´æ˜ï¼‰
                            procurement_stats = marked_df['æ˜¯å¦é›†é‡‡'].value_counts()
                            st.subheader("é›†é‡‡æ ‡è®°ç»Ÿè®¡")
                            st.write("æ³¨æ„ï¼šç©ºç™½è¡¨ç¤ºå‘è´§æ˜ç»†ä¸­æœ‰ä½†ä¾›åº”å•†è®¢å•ä¸­æ²¡æœ‰çš„è®°å½•")
                            st.write(procurement_stats)
                            # å•ç‹¬ç»Ÿè®¡ç©ºç™½æ•°é‡
                            blank_count = len(marked_df[marked_df['æ˜¯å¦é›†é‡‡'] == ''])
                            if blank_count > 0:
                                st.info(f"å…±æœ‰ {blank_count} è¡Œè®°å½•åœ¨ä¾›åº”å•†è®¢å•ä¸­æœªæ‰¾åˆ°å¯¹åº”ä¿¡æ¯ï¼ˆæ˜¾ç¤ºä¸ºç©ºç™½ï¼‰")
                            
                            # æ˜¾ç¤ºéƒ¨åˆ†æ ‡è®°ç»“æœ
                            st.subheader("æ ‡è®°ç»“æœé¢„è§ˆ")
                            preview_df = marked_df[['é¢†ç”¨è¯´æ˜', 'æ”¶è´§äºº', 'æ”¶è´§äººç”µè¯', 'äº§å“åç§°', 'æ•°é‡', 'æ˜¯å¦é›†é‡‡']].head(20)
                            st.dataframe(preview_df)
                            
                            # æä¾›ä¸‹è½½
                            output_file = f"å‘è´§æ˜ç»†_å«é›†é‡‡ä¿¡æ¯_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            save_with_formatting(marked_df, output_file)
                            
                            with open(output_file, "rb") as file:
                                st.download_button(
                                    label="ä¸‹è½½æ ‡è®°ç»“æœ",
                                    data=file,
                                    file_name=output_file,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        else:
                            st.error("æ ‡è®°é›†é‡‡ä¿¡æ¯æ—¶å‡ºç°é”™è¯¯")
                    else:
                        st.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ä¾›åº”å•†è®¢å•æ–‡ä»¶")

elif app_mode == "å¯¼å…¥ç›´é‚®æ˜ç»†åˆ°ä¸‰æ‹©å¯¼å•":
    st.header("å¯¼å…¥ç›´é‚®æ˜ç»†åˆ°ä¸‰æ‹©å¯¼å•")
    st.info("è¯·æŒ‰æ­¥éª¤æ“ä½œï¼š1.ä¸Šä¼ ä¸‰æ‹©å¯¼å• 2.ä¸Šä¼ ç›´é‚®æ–‡ä»¶å¹¶é€‰æ‹©åˆ—æ˜ å°„")
    
    # å•†å“åˆ—è¡¨
    product_list = [
        "å¥¥å…‹æ–¯ï¼ˆAUXï¼‰ é™¤è¨ä»ª 90W ï¼ˆè®¡ä»·å•ä½ï¼šå°ï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰  ç›’è£…æŠ½çº¸  ï¼ˆè®¡ä»·å•ä½ï¼šç›’ï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ ç¯ä¿å¡‘æ–™è¢‹  50ä¸ª/æ† 300ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ ä¸¤ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ æ¹¿çº¸å·¾ 10ç‰‡/åŒ… ï¼ˆè®¡ä»·å•ä½ï¼šåŒ…ï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ å››ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ å››ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¤©å¶å“ç³»ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ å¤©å¶åæ¯«å…‹   ä¸¤æ¡è£…çº¸è¢‹ ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¸¸è§„æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆç»†æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆä¸­æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "å“èƒœï¼ˆPISENï¼‰ æ•°æ®çº¿ä¸‰åˆä¸€å……ç”µçº¿100W  ä¸€æ‹–ä¸‰ ï¼ˆè®¡ä»·å•ä½ï¼šæ¡ï¼‰ æœ‰è‰²",
        "å‰ƒé¡»åˆ€ä¾¿æºåˆé‡‘ç”µåŠ¨åˆ®èƒ¡åˆ€ç”·å£«  MINI 2.0 ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ é¢œè‰²éšæœº"
    ]
    
    # åˆå§‹åŒ–session state
    if 'processed_data_list' not in st.session_state:
        st.session_state.processed_data_list = []
    if 'show_import_success' not in st.session_state:
        st.session_state.show_import_success = False
    if 'selected_product' not in st.session_state:
        st.session_state.selected_product = ""
    if 'product_quantity' not in st.session_state:
        st.session_state.product_quantity = 1
    if 'download_triggered' not in st.session_state:
        st.session_state.download_triggered = False
    
    # æ­¥éª¤1ï¼šä¸Šä¼ ä¸‰æ‹©å¯¼å•
    sanze_file = st.file_uploader("1. ä¸Šä¼ ä¸‰æ‹©å¯¼å•æ–‡ä»¶", type=["xlsx"], key="sanze_file")
    
    if sanze_file:
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä»¥ç¡®ä¿å¯å†™æƒé™
            with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp_file:
                tmp_file.write(sanze_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ä»ä¸´æ—¶æ–‡ä»¶è¯»å–ä¸‰æ‹©å¯¼å•
            sanze_df = pd.read_excel(tmp_file_path)
            st.success(f"ä¸‰æ‹©å¯¼å•å·²åŠ è½½ï¼ˆå…±{len(sanze_df)}è¡Œï¼‰")
            
            # ç¡®ä¿æœ‰å®¢æˆ·å¤‡æ³¨åˆ—å’Œè´§å“åç§°ã€æ•°é‡åˆ—
            if 'å®¢æˆ·å¤‡æ³¨' not in sanze_df.columns:
                sanze_df['å®¢æˆ·å¤‡æ³¨'] = ''
            if 'è´§å“åç§°' not in sanze_df.columns:
                sanze_df['è´§å“åç§°'] = ''
            if 'æ•°é‡' not in sanze_df.columns:
                sanze_df['æ•°é‡'] = ''
            
            # æ­¥éª¤2ï¼šå¤„ç†ç›´é‚®æ–‡ä»¶
            st.subheader("2. å¤„ç†ç›´é‚®æ˜ç»†æ–‡ä»¶")
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ ç›´é‚®æ˜ç»†æ–‡ä»¶", 
                type=["xlsx"],
                key="direct_mail_current"
            )
            
            if uploaded_file:
                # æ·»åŠ åˆ—åè¡Œé€‰æ‹©åŠŸèƒ½
                st.subheader("3. é€‰æ‹©åˆ—åæ‰€åœ¨è¡Œ")
                header_option = st.radio(
                    "è¯·é€‰æ‹©åˆ—åæ‰€åœ¨çš„è¡Œï¼ˆæŸ¥çœ‹ä¸‹é¢çš„é¢„è§ˆæ¥ç¡®å®šï¼‰",
                    options=[0, 1],
                    format_func=lambda x: f"ç¬¬{x+1}è¡Œ",
                    key="header_option"
                )
                
                # è¯»å–å‰3è¡Œæ•°æ®ç”¨äºé¢„è§ˆ
                preview_df = pd.read_excel(uploaded_file, header=None, nrows=3)
                st.write("å‰ä¸‰è¡Œæ•°æ®é¢„è§ˆï¼ˆç”¨äºç¡®å®šåˆ—åæ‰€åœ¨è¡Œï¼‰:")
                st.dataframe(preview_df)
                
                # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„åˆ—åè¡Œé‡æ–°è¯»å–æ•°æ®
                df = pd.read_excel(uploaded_file, header=header_option)
                
                st.write(f"ä½¿ç”¨ç¬¬{header_option+1}è¡Œä½œä¸ºåˆ—ååçš„æ•°æ®é¢„è§ˆ:")
                st.dataframe(df.head(5))
                
                # å•†å“é€‰æ‹©ç•Œé¢ï¼ˆåªèƒ½é€‰æ‹©ä¸€ä¸ªå•†å“ï¼‰
                st.subheader("4. é€‰æ‹©å•†å“å’Œæ•°é‡")
                selected_product = st.selectbox("é€‰æ‹©å•†å“", [""] + product_list, 
                                              index=product_list.index(st.session_state.selected_product) + 1 
                                              if st.session_state.selected_product in product_list else 0,
                                              key="product_selector")
                st.session_state.selected_product = selected_product
                
                product_quantity = st.number_input("æ•°é‡", min_value=1, value=st.session_state.product_quantity, key="quantity_selector")
                st.session_state.product_quantity = product_quantity
                
                # åˆ—é€‰æ‹©ç•Œé¢
                st.subheader("5. è¯·é€‰æ‹©å¯¹åº”åˆ—")
                cols = st.columns(2)
                with cols[0]:
                    name_col = st.selectbox("æ”¶è´§äººåˆ—", df.columns, key="name_col")
                    phone_col = st.selectbox("ç”µè¯åˆ—", df.columns, key="phone_col")
                with cols[1]:
                    address_col = st.selectbox("åœ°å€åˆ—", df.columns, key="address_col")
                    shop_col = st.selectbox("åº—ååˆ—", df.columns, key="shop_col")
                
                # å¤„ç†æŒ‰é’®
                if st.button("å¤„ç†å½“å‰æ–‡ä»¶"):
                    processed = []
                    for _, row in df.iterrows():
                        item = {
                            'æ”¶è´§äºº': str(row[name_col]).strip() if pd.notna(row[name_col]) else '',
                            'æ‰‹æœº': str(row[phone_col]).strip() if pd.notna(row[phone_col]) else '',
                            'æ”¶è´§åœ°å€': str(row[address_col]).strip() if pd.notna(row[address_col]) else '',
                            'å®¢æˆ·å¤‡æ³¨': str(row[shop_col]).strip() if pd.notna(row[shop_col]) else '',
                            'å•†å“åç§°': st.session_state.selected_product,
                            'å•†å“æ•°é‡': st.session_state.product_quantity
                        }
                        if item['æ”¶è´§äºº'] or item['æ‰‹æœº']:
                            processed.append(item)
                    
                    # å°†å½“å‰å¤„ç†çš„æ–‡ä»¶æ•°æ®æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    st.session_state.processed_data_list.append({
                        'filename': uploaded_file.name,
                        'data': processed
                    })
                    st.session_state.show_import_success = False
                    st.session_state.download_triggered = False
                    st.success(f"æˆåŠŸå¤„ç†{len(processed)}è¡Œæ•°æ®")
                    
                    # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„DataFrameç”¨äºæ˜¾ç¤º
                    display_data = []
                    for item in processed[:10]:  # åªæ˜¾ç¤ºå‰10è¡Œ
                        display_item = {
                            'æ”¶è´§äºº': item['æ”¶è´§äºº'],
                            'æ‰‹æœº': item['æ‰‹æœº'],
                            'æ”¶è´§åœ°å€': item['æ”¶è´§åœ°å€'],
                            'å®¢æˆ·å¤‡æ³¨': item['å®¢æˆ·å¤‡æ³¨'],
                            'å•†å“åç§°': item['å•†å“åç§°'],
                            'å•†å“æ•°é‡': item['å•†å“æ•°é‡']
                        }
                        display_data.append(display_item)
                    
                    display_df = pd.DataFrame(display_data)
                    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
                    for col in display_df.columns:
                        display_df[col] = display_df[col].astype(str)
                    st.dataframe(display_df)
                
                # æ˜¾ç¤ºå·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨å’Œå¯¼å…¥æŒ‰é’®
                if st.session_state.processed_data_list:
                    st.subheader("å·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨")
                    for i, item in enumerate(st.session_state.processed_data_list):
                        st.write(f"{i+1}. {item['filename']} ({len(item['data'])} è¡Œæ•°æ®)")
                    
                    # æ·»åŠ åˆ°ä¸‰æ‹©å¯¼å•æŒ‰é’®æ”¾åœ¨å·²å¤„ç†æ–‡ä»¶åˆ—è¡¨ä¸‹æ–¹
                    if st.button("ç¡®è®¤å¯¼å…¥åˆ°ä¸‰æ‹©å¯¼å•"):
                        total_imported = 0
                        for processed_item in st.session_state.processed_data_list:
                            processed_data = processed_item['data']
                            for item in processed_data:
                                new_row = {col: '' for col in sanze_df.columns}
                                new_row.update({
                                    'æ”¶è´§äºº': item['æ”¶è´§äºº'],
                                    'æ‰‹æœº': item['æ‰‹æœº'],
                                    'æ”¶è´§åœ°å€': item['æ”¶è´§åœ°å€'],
                                    'å®¢æˆ·å¤‡æ³¨': item['å®¢æˆ·å¤‡æ³¨'],
                                    'è´§å“åç§°': item['å•†å“åç§°'],
                                    'æ•°é‡': item['å•†å“æ•°é‡']
                                })
                                sanze_df.loc[len(sanze_df)] = new_row
                                total_imported += 1
                        
                        st.session_state.show_import_success = True
                        st.session_state.download_triggered = False
                
                if st.session_state.show_import_success:
                    st.success(f"å¯¼å…¥å®Œæˆï¼Œä¸‰æ‹©å¯¼å•ç°æœ‰{len(sanze_df)}è¡Œ")
                    
                    # ä¸‹è½½æ›´æ–°åçš„æ–‡ä»¶ï¼Œæ–‡ä»¶åç²¾ç¡®åˆ°ç§’
                    output = f"ä¸‰æ‹©å¯¼å•_æ›´æ–°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    sanze_df.to_excel(output, index=False)
                    
                    with open(output, "rb") as f:
                        st.download_button("ä¸‹è½½æ›´æ–°åçš„ä¸‰æ‹©å¯¼å•", f, file_name=output)
                        
                    # å¯¼å…¥å®Œæˆåæ¸…ç©ºå·²å¤„ç†æ•°æ®åˆ—è¡¨
                    if st.button("æ¸…ç©ºå·²å¤„ç†æ–‡ä»¶åˆ—è¡¨å¹¶å¼€å§‹ä¸‹ä¸€è½®å¯¼å…¥"):
                        st.session_state.processed_data_list = []
                        st.session_state.show_import_success = False
                        st.session_state.selected_product = ""
                        st.session_state.product_quantity = 1
                        st.session_state.download_triggered = False
                        st.rerun()
                        
        except Exception as e:
            st.error(f"å¤„ç†ä¸‰æ‹©å¯¼å•æ—¶å‡ºé”™: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

# æ·»åŠ æ–°çš„åŠŸèƒ½æ¨¡å—
elif app_mode == "å•†å“åç§°æ ‡å‡†åŒ–":
    st.header("å•†å“åç§°æ ‡å‡†åŒ–")
    st.info("æ­¤åŠŸèƒ½ç”¨äºå°†å‘è´§æ˜ç»†ä¸­çš„ä¸è§„èŒƒå•†å“åç§°æ ‡å‡†åŒ–ä¸ºç»Ÿä¸€æ ¼å¼")
    
    # å•†å“åˆ—è¡¨ï¼ˆæ ‡å‡†åç§°ï¼‰
    product_list = [
        "å¥¥å…‹æ–¯ï¼ˆAUXï¼‰ é™¤è¨ä»ª 90W ï¼ˆè®¡ä»·å•ä½ï¼šå°ï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰  ç›’è£…æŠ½çº¸  ï¼ˆè®¡ä»·å•ä½ï¼šç›’ï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ ç¯ä¿å¡‘æ–™è¢‹  50ä¸ª/æ† 300ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ ä¸¤ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ æ¹¿çº¸å·¾ 10ç‰‡/åŒ… ï¼ˆè®¡ä»·å•ä½ï¼šåŒ…ï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ å››ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ å››ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¤©å¶å“ç³»ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ å¤©å¶åæ¯«å…‹   ä¸¤æ¡è£…çº¸è¢‹ ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¸¸è§„æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆç»†æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆä¸­æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
        "å“èƒœï¼ˆPISENï¼‰ æ•°æ®çº¿ä¸‰åˆä¸€å……ç”µçº¿100W  ä¸€æ‹–ä¸‰ ï¼ˆè®¡ä»·å•ä½ï¼šæ¡ï¼‰",
        "æœ‰è‰² å‰ƒé¡»åˆ€ä¾¿æºåˆé‡‘ç”µåŠ¨åˆ®èƒ¡åˆ€ç”·å£«  MINI 2.0 ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ é¢œè‰²éšæœº"
    ]
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ å‘è´§æ˜ç»†æ–‡ä»¶", type=["xlsx"], key="standardize_products")
    
    if uploaded_file:
        try:
            # è¯»å–æ–‡ä»¶
            df = pd.read_excel(uploaded_file)
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
            for col in df.columns:
                df[col] = df[col].astype(str)
            
            st.subheader("åŸå§‹æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10))
            
            # é€‰æ‹©äº§å“åç§°åˆ— - æ·»åŠ å¯¹"è´§å“åç§°"åˆ—çš„æ”¯æŒ
            if 'è´§å“åç§°' in df.columns:
                product_col = 'è´§å“åç§°'
            elif 'äº§å“åç§°' in df.columns:
                product_col = 'äº§å“åç§°'
            else:
                product_col = st.selectbox("é€‰æ‹©åŒ…å«äº§å“åç§°çš„åˆ—", df.columns)
            
            # æ˜¾ç¤ºå½“å‰äº§å“åç§°çš„å”¯ä¸€å€¼
            unique_products = df[product_col].unique()
            st.subheader("å½“å‰æ–‡ä»¶ä¸­çš„äº§å“åç§°")
            st.write(f"å…±æœ‰ {len(unique_products)} ä¸ªä¸åŒçš„äº§å“åç§°:")
            st.dataframe(pd.DataFrame(unique_products, columns=['äº§å“åç§°']))
            
            # å¤„ç†æ ‡å‡†åŒ–
            if st.button("æ‰§è¡Œæ ‡å‡†åŒ–"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå•†å“åç§°æ ‡å‡†åŒ–..."):
                    # åˆ›å»ºæ ‡å‡†åŒ–æ˜ å°„
                    standardized_mapping = {}
                    
                    # å®šä¹‰ç‰¹å®šçš„æ˜ å°„è§„åˆ™
                    special_mappings = {
                        "ç¡¬ç›’çº¸æŠ½ï¼ˆ130æŠ½ï¼‰ï¼ˆ250506ï¼‰": "é»„é‡‘è‘‰  ç›’è£…æŠ½çº¸  ï¼ˆè®¡ä»·å•ä½ï¼šç›’ï¼‰ å›½äº§å®šåˆ¶",
                        "æ¹¿å·¾ï¼ˆ10ç‰‡/åŒ…ï¼‰ï¼ˆ250506ï¼‰": "é»„é‡‘è‘‰ æ¹¿çº¸å·¾ 10ç‰‡/åŒ… ï¼ˆè®¡ä»·å•ä½ï¼šåŒ…ï¼‰ å›½äº§å®šåˆ¶"
                    }
                    
                    # å®šä¹‰å…³é”®è¯æ˜ å°„ï¼Œç”¨äºæå–å•†å“çš„å”¯ä¸€å…³é”®è¯è¿›è¡ŒåŒ¹é…
                    keyword_mappings = {
                        "é™¤è¨ä»ª": "å¥¥å…‹æ–¯ï¼ˆAUXï¼‰ é™¤è¨ä»ª 90W ï¼ˆè®¡ä»·å•ä½ï¼šå°ï¼‰",
                        "æŠ½": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰  ç›’è£…æŠ½çº¸  ï¼ˆè®¡ä»·å•ä½ï¼šç›’ï¼‰",
                        "å¡‘æ–™è¢‹": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ ç¯ä¿å¡‘æ–™è¢‹  50ä¸ª/æ† 300ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "ä¸¤ç›’è£…ç¿»ç›–å¼ç¤¼ç›’": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ ä¸¤ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "æ¹¿çº¸å·¾": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ æ¹¿çº¸å·¾ 10ç‰‡/åŒ… ï¼ˆè®¡ä»·å•ä½ï¼šåŒ…ï¼‰",
                        "å››ç›’è£…ç¿»ç›–å¼ç¤¼ç›’": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ å››ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "å››ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¤©å¶å“ç³»ï¼‰": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ å››ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¤©å¶å“ç³»ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "å¤©å¶åæ¯«å…‹": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ å¤©å¶åæ¯«å…‹   ä¸¤æ¡è£…çº¸è¢‹ ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¸¸è§„æ¬¾ï¼‰": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¸¸è§„æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆç»†æ”¯æ¬¾ï¼‰": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆç»†æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆä¸­æ”¯æ¬¾ï¼‰": "å›½äº§å®šåˆ¶ é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆä¸­æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰",
                        "æ•°æ®çº¿ä¸‰åˆä¸€å……ç”µçº¿100W": "å“èƒœï¼ˆPISENï¼‰ æ•°æ®çº¿ä¸‰åˆä¸€å……ç”µçº¿100W  ä¸€æ‹–ä¸‰ ï¼ˆè®¡ä»·å•ä½ï¼šæ¡ï¼‰",
                        "å‰ƒé¡»åˆ€": "æœ‰è‰² å‰ƒé¡»åˆ€ä¾¿æºåˆé‡‘ç”µåŠ¨åˆ®èƒ¡åˆ€ç”·å£«  MINI 2.0 ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ é¢œè‰²éšæœº"
                    }
                    
                    # å¯¹æ¯ä¸ªä¸è§„èŒƒçš„äº§å“åç§°è¿›è¡ŒåŒ¹é…
                    for product in unique_products:
                        # é¦–å…ˆæ£€æŸ¥ç‰¹æ®Šæ˜ å°„è§„åˆ™
                        if product in special_mappings:
                            standardized_mapping[product] = special_mappings[product]
                            continue
                            
                        # ç„¶åæ£€æŸ¥æ˜¯å¦èƒ½é€šè¿‡å…³é”®è¯åŒ¹é…
                        matched = False
                        for keyword, standard_name in keyword_mappings.items():
                            # å¦‚æœäº§å“åç§°åŒ…å«å…³é”®è¯ï¼Œåˆ™åŒ¹é…
                            if keyword in product:
                                standardized_mapping[product] = standard_name
                                matched = True
                                break
                        
                        # å¦‚æœé€šè¿‡å…³é”®è¯æ— æ³•åŒ¹é…ï¼Œåˆ™ä½¿ç”¨æ¨¡ç³ŠåŒ¹é…
                        if not matched:
                            # å¯¼å…¥difflibç”¨äºæ¨¡ç³ŠåŒ¹é…
                            import difflib
                            matches = difflib.get_close_matches(product, product_list, n=1, cutoff=0.6)
                            if matches:
                                standardized_mapping[product] = matches[0]
                            else:
                                # å¦åˆ™ä¿æŒåŸåç§°
                                standardized_mapping[product] = product
                    
                    # åº”ç”¨æ ‡å‡†åŒ–æ˜ å°„
                    df['æ ‡å‡†åŒ–äº§å“åç§°'] = df[product_col].map(standardized_mapping)
                    
                    # æ˜¾ç¤ºæ ‡å‡†åŒ–ç»“æœ
                    st.subheader("æ ‡å‡†åŒ–ç»“æœ")
                    st.success("å•†å“åç§°æ ‡å‡†åŒ–å®Œæˆï¼")
                    
                    # æ˜¾ç¤ºæ˜ å°„å…³ç³»
                    mapping_df = pd.DataFrame(list(standardized_mapping.items()), columns=['åŸå§‹åç§°', 'æ ‡å‡†åŒ–åç§°'])
                    st.write("åç§°æ˜ å°„å…³ç³»:")
                    st.dataframe(mapping_df)
                    
                    # æ˜¾ç¤ºæ ‡å‡†åŒ–åçš„æ•°æ®é¢„è§ˆ
                    st.subheader("æ ‡å‡†åŒ–åæ•°æ®é¢„è§ˆ")
                    st.dataframe(df[['æ ‡å‡†åŒ–äº§å“åç§°'] + [col for col in df.columns if col != 'æ ‡å‡†åŒ–äº§å“åç§°']].head(10))
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    unchanged_count = sum(1 for k, v in standardized_mapping.items() if k == v)
                    changed_count = len(standardized_mapping) - unchanged_count
                    st.info(f"æ ‡å‡†åŒ–ç»Ÿè®¡: {changed_count} ä¸ªåç§°å·²ä¿®æ”¹, {unchanged_count} ä¸ªåç§°ä¿æŒä¸å˜")
                    
                    # æä¾›ä¸‹è½½
                    output_file = f"æ ‡å‡†åŒ–å‘è´§æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    df.to_excel(output_file, index=False)
                    
                    with open(output_file, "rb") as file:
                        st.download_button(
                            label="ä¸‹è½½æ ‡å‡†åŒ–ç»“æœ",
                            data=file,
                            file_name=output_file,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                        
        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

elif app_mode == "å¢å¼ºç‰ˆVLOOKUP":
    st.header("å¢å¼ºç‰ˆVLOOKUP")
    st.info("æ­¤åŠŸèƒ½å…è®¸æ‚¨ä»å‚è€ƒè¡¨ä¸­æ‰¹é‡åŒ¹é…å¤šä¸ªåˆ—åˆ°ä¸»è¡¨ä¸­")
    
    # åˆå§‹åŒ–session state
    if 'vlookup_processed' not in st.session_state:
        st.session_state.vlookup_processed = False
    if 'vlookup_result' not in st.session_state:
        st.session_state.vlookup_result = None
    
    col1, col2 = st.columns(2)
    
    with col1:
        main_file = st.file_uploader("ä¸Šä¼ ä¸»è¡¨æ–‡ä»¶", type=["xlsx"], key="main_file")
    
    with col2:
        reference_file = st.file_uploader("ä¸Šä¼ å‚è€ƒè¡¨æ–‡ä»¶", type=["xlsx"], key="reference_file")
    
    if main_file and reference_file:
        try:
            # è¯»å–ä¸¤ä¸ªæ–‡ä»¶
            main_df = pd.read_excel(main_file)
            reference_df = pd.read_excel(reference_file)
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
            for col in main_df.columns:
                main_df[col] = main_df[col].astype(str)
                
            for col in reference_df.columns:
                reference_df[col] = reference_df[col].astype(str)
            
            st.subheader("ä¸»è¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(main_df.head(10))
            
            st.subheader("å‚è€ƒè¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(reference_df.head(10))
            
            # é€‰æ‹©åŒ¹é…åˆ—
            st.subheader("é…ç½®åŒ¹é…å‚æ•°")
            
            # è·å–æ‰€æœ‰åˆ—å
            main_columns = main_df.columns.tolist()
            reference_columns = reference_df.columns.tolist()
            
            # é€‰æ‹©ç”¨äºåŒ¹é…çš„åˆ—ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
            st.write("é€‰æ‹©ç”¨äºåŒ¹é…çš„åˆ—ï¼ˆæ”¯æŒå¤šåˆ—ç»„åˆåŒ¹é…ï¼‰:")
            match_cols_main = st.multiselect("ä¸»è¡¨ä¸­çš„åŒ¹é…åˆ—", main_columns, key="match_cols_main", max_selections=len(main_columns))
            match_cols_ref = st.multiselect("å‚è€ƒè¡¨ä¸­çš„åŒ¹é…åˆ—ï¼ˆè¯·æŒ‰ä¸ä¸»è¡¨ç›¸åŒçš„é¡ºåºé€‰æ‹©ï¼‰", reference_columns, key="match_cols_ref", max_selections=len(reference_columns))
            
            # éªŒè¯åŒ¹é…åˆ—é€‰æ‹©
            if len(match_cols_main) != len(match_cols_ref):
                st.warning("ä¸»è¡¨å’Œå‚è€ƒè¡¨çš„åŒ¹é…åˆ—æ•°é‡å¿…é¡»ç›¸åŒ")
            elif len(match_cols_main) == 0:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—ç”¨äºåŒ¹é…")
            else:
                # æ˜¾ç¤ºåŒ¹é…åˆ—å¯¹åº”å…³ç³»
                st.write("åŒ¹é…åˆ—å¯¹åº”å…³ç³»:")
                match_df = pd.DataFrame({
                    'ä¸»è¡¨åˆ—å': match_cols_main,
                    'å‚è€ƒè¡¨åˆ—å': match_cols_ref
                })
                st.table(match_df)
                
                # é€‰æ‹©è¦ä»å‚è€ƒè¡¨æ·»åŠ çš„åˆ—
                st.write("é€‰æ‹©è¦ä»å‚è€ƒè¡¨æ·»åŠ åˆ°ä¸»è¡¨çš„åˆ—:")
                # æ’é™¤å·²ç”¨äºåŒ¹é…çš„åˆ—
                available_columns = [col for col in reference_columns if col not in match_cols_ref]
                columns_to_add = st.multiselect("é€‰æ‹©åˆ—", available_columns, key="columns_to_add")
                
                # é€‰æ‹©åŒ¹é…æ–¹å¼
                st.write("åŒ¹é…æ–¹å¼:")
                join_type = st.radio("é€‰æ‹©è¿æ¥æ–¹å¼", 
                                    ["LEFT JOIN (ä¿ç•™ä¸»è¡¨æ‰€æœ‰è¡Œ)", 
                                     "INNER JOIN (åªä¿ç•™ä¸¤è¡¨åŒ¹é…çš„è¡Œ)"], 
                                    key="join_type")
                
                # å¤„ç†é‡å¤é¡¹é€‰é¡¹
                st.subheader("é‡å¤é¡¹å¤„ç†")
                handle_duplicates = st.radio(
                    "å¦‚ä½•å¤„ç†å‚è€ƒè¡¨ä¸­çš„é‡å¤åŒ¹é…è®°å½•",
                    ["ä¿ç•™ç¬¬ä¸€æ¡è®°å½•", "åˆå¹¶æ‰€æœ‰è®°å½•ï¼ˆå¯èƒ½å¯¼è‡´è¡Œæ•°å¢åŠ ï¼‰"],
                    index=0,
                    key="vlookup_handle_duplicates"
                )
                
                if st.button("æ‰§è¡Œå¢å¼ºVLOOKUP"):
                    if columns_to_add:
                        with st.spinner("æ­£åœ¨æ‰§è¡Œå¢å¼ºVLOOKUP..."):
                            try:
                                # å¤„ç†å‚è€ƒè¡¨ä¸­çš„é‡å¤è®°å½•
                                if handle_duplicates == "ä¿ç•™ç¬¬ä¸€æ¡è®°å½•":
                                    # å¯¹äºæ¯ä¸ªåŒ¹é…é”®ï¼Œåªä¿ç•™ç¬¬ä¸€æ¡è®°å½•
                                    reference_df_unique = reference_df.drop_duplicates(subset=match_cols_ref, keep='first')
                                    st.info(f"å‚è€ƒè¡¨ä¸­é‡å¤çš„åŒ¹é…è®°å½•å·²è¢«ç§»é™¤ï¼Œå‰©ä½™ {len(reference_df_unique)} æ¡è®°å½•")
                                else:
                                    reference_df_unique = reference_df
                                    st.info(f"ä¿ç•™å‚è€ƒè¡¨ä¸­çš„æ‰€æœ‰è®°å½•ï¼Œå…± {len(reference_df_unique)} æ¡è®°å½•")
                                
                                # ä¿å­˜ä¸»è¡¨çš„åŸå§‹ç´¢å¼•
                                main_df_with_index = main_df.reset_index()
                                
                                # æ‰§è¡Œå¢å¼ºç‰ˆVLOOKUP
                                if join_type == "LEFT JOIN (ä¿ç•™ä¸»è¡¨æ‰€æœ‰è¡Œ)":
                                    # ä½¿ç”¨left joinç¡®ä¿ä¿ç•™ä¸»è¡¨çš„æ‰€æœ‰è¡Œå’Œé¡ºåº
                                    merged_temp = pd.merge(main_df_with_index, 
                                                         reference_df_unique[match_cols_ref + columns_to_add], 
                                                         left_on=match_cols_main, 
                                                         right_on=match_cols_ref, 
                                                         how='left',
                                                         sort=False)  # ä¿æŒåŸæœ‰é¡ºåº
                                else:
                                    # INNER JOIN
                                    merged_temp = pd.merge(main_df_with_index, 
                                                         reference_df_unique[match_cols_ref + columns_to_add], 
                                                         left_on=match_cols_main, 
                                                         right_on=match_cols_ref, 
                                                         how='inner',
                                                         sort=False)  # ä¿æŒåŸæœ‰é¡ºåº
                                
                                # æ¢å¤åŸå§‹ç´¢å¼•å¹¶æ’åºï¼Œç¡®ä¿è¡Œé¡ºåºä¸ä¸»è¡¨ä¸€è‡´
                                result_df = merged_temp.sort_values('index').drop('index', axis=1).reset_index(drop=True)
                                
                                # ç¡®ä¿ç»“æœDataFrameçš„æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                                for col in result_df.columns:
                                    result_df[col] = result_df[col].astype(str)
                                
                                st.success("å¢å¼ºVLOOKUPæ‰§è¡Œå®Œæˆï¼")
                                st.subheader("ç»“æœç»Ÿè®¡")
                                st.write(f"åŸå§‹ä¸»è¡¨è¡Œæ•°: {len(main_df)}")
                                st.write(f"åŒ¹é…åç»“æœè¡Œæ•°: {len(result_df)}")
                                
                                if len(result_df) > len(main_df):
                                    st.warning("æ³¨æ„ï¼šç»“æœè¡Œæ•°å¢åŠ ï¼Œè¿™æ˜¯å› ä¸ºæŸäº›è®°å½•åœ¨å‚è€ƒè¡¨ä¸­æœ‰å¤šæ¡åŒ¹é…è®°å½•")
                                
                                st.subheader("ç»“æœé¢„è§ˆ")
                                st.dataframe(result_df.head(20))
                                
                                # æä¾›ä¸‹è½½
                                output_file = f"å¢å¼ºVLOOKUPç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                                result_df.to_excel(output_file, index=False)
                                
                                with open(output_file, "rb") as file:
                                    st.download_button(
                                        label="ä¸‹è½½ç»“æœæ–‡ä»¶",
                                        data=file,
                                        file_name=output_file,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                            except Exception as e:
                                st.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                                import traceback
                                st.error(traceback.format_exc())
                    else:
                        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—æ·»åŠ åˆ°ä¸»è¡¨ä¸­")
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

elif app_mode == "ç‰©æµå•å·åŒ¹é…":
    st.header("ç‰©æµå•å·åŒ¹é…")
    st.info("æ­¤åŠŸèƒ½ç”¨äºå°†ç‰©æµå•å·è¡¨ä¸­çš„å¿«é€’å…¬å¸ã€å•å·å’Œé¢å¤–å•å·ä¿¡æ¯åŒ¹é…åˆ°å¾…å‘è´§æ˜ç»†è¡¨ä¸­")
    
    col1, col2 = st.columns(2)
    
    with col1:
        pending_shipment_file = st.file_uploader("ä¸Šä¼ å¾…å‘è´§æ˜ç»†è¡¨", type=["xlsx"], key="pending_shipment_file")
    
    with col2:
        logistics_file = st.file_uploader("ä¸Šä¼ ç‰©æµå•å·è¡¨", type=["xlsx"], key="logistics_file")
    
    if pending_shipment_file and logistics_file:
        try:
            # è¯»å–ä¸¤ä¸ªæ–‡ä»¶
            pending_shipment_df = pd.read_excel(pending_shipment_file)
            logistics_df = pd.read_excel(logistics_file)
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
            for col in pending_shipment_df.columns:
                pending_shipment_df[col] = pending_shipment_df[col].astype(str)
                
            for col in logistics_df.columns:
                logistics_df[col] = logistics_df[col].astype(str)
            
            st.subheader("å¾…å‘è´§æ˜ç»†è¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(pending_shipment_df.head(10))
            
            st.subheader("ç‰©æµå•å·è¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(logistics_df.head(10))
            
            # æ˜¾ç¤ºåˆ—å
            st.subheader("åˆ—åä¿¡æ¯")
            with st.expander("ç‚¹å‡»å±•å¼€/æ”¶èµ·åˆ—åè¯¦æƒ…"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write("å¾…å‘è´§æ˜ç»†è¡¨åˆ—å:")
                    st.write(list(pending_shipment_df.columns))
                with col2:
                    st.write("ç‰©æµå•å·è¡¨åˆ—å:")
                    st.write(list(logistics_df.columns))
            
            # è‡ªåŠ¨åŒ¹é…å…³é”®åˆ—
            st.subheader("å…³é”®åˆ—åŒ¹é…")
            
            # å®šä¹‰å¯èƒ½çš„åˆ—å
            pending_shipment_name_cols = ['æ”¶è´§äºº', 'æ”¶ä»¶äºº', 'å®¢æˆ·åç§°', 'å§“å']
            logistics_name_cols = ['æ”¶ä»¶äºº', 'æ”¶è´§äºº', 'å®¢æˆ·åç§°', 'å§“å']
            
            # è‡ªåŠ¨æ£€æµ‹åŒ¹é…åˆ—ï¼Œä¼˜å…ˆé€‰æ‹©"æ”¶è´§äºº"
            pending_name_col = None
            logistics_name_col = None
            
            # ä¼˜å…ˆæ£€æŸ¥"æ”¶è´§äºº"åˆ—
            if 'æ”¶è´§äºº' in pending_shipment_df.columns:
                pending_name_col = 'æ”¶è´§äºº'
            else:
                for col in pending_shipment_df.columns:
                    if col in pending_shipment_name_cols:
                        pending_name_col = col
                        break
            
            if 'æ”¶è´§äºº' in logistics_df.columns:
                logistics_name_col = 'æ”¶è´§äºº'
            else:
                for col in logistics_df.columns:
                    if col in logistics_name_cols:
                        logistics_name_col = col
                        break
            
            # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„åˆ—
            st.write("è‡ªåŠ¨æ£€æµ‹åˆ°çš„åŒ¹é…åˆ—:")
            with st.expander("ç‚¹å‡»é€‰æ‹©åŒ¹é…åˆ—", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    pending_name_select = st.selectbox(
                        "å¾…å‘è´§æ˜ç»†è¡¨ä¸­çš„æ”¶ä»¶äººåˆ—", 
                        pending_shipment_df.columns, 
                        index=pending_shipment_df.columns.tolist().index(pending_name_col) if pending_name_col else 0,
                        key="pending_name_select"
                    )
                with col2:
                    logistics_name_select = st.selectbox(
                        "ç‰©æµå•å·è¡¨ä¸­çš„æ”¶ä»¶äººåˆ—", 
                        logistics_df.columns, 
                        index=logistics_df.columns.tolist().index(logistics_name_col) if logistics_name_col else 0,
                        key="logistics_name_select"
                    )
            
            # é€‰æ‹©è¦æ·»åŠ çš„åˆ—
            st.subheader("é€‰æ‹©è¦æ·»åŠ çš„åˆ—")
            available_columns = [col for col in logistics_df.columns if col not in [logistics_name_select]]
            
            # è®¾ç½®é»˜è®¤é€‰ä¸­çš„åˆ—
            default_columns = []
            common_logistics_columns = ['ç‰©æµå…¬å¸', 'ç‰©æµå•å·', 'é¢å¤–ç‰©æµå•å·']
            for col in common_logistics_columns:
                if col in available_columns:
                    default_columns.append(col)
            
            with st.expander("ç‚¹å‡»é€‰æ‹©è¦æ·»åŠ çš„åˆ—", expanded=True):
                columns_to_add = st.multiselect(
                    "é€‰æ‹©è¦ä»ç‰©æµå•å·è¡¨æ·»åŠ åˆ°å¾…å‘è´§æ˜ç»†è¡¨çš„åˆ—",
                    available_columns,
                    default=default_columns,
                    key="columns_to_add"
                )
                st.write("å·²é€‰æ‹©è¦æ·»åŠ çš„åˆ—:", columns_to_add)
            
            # å¤„ç†é‡å¤é¡¹é€‰é¡¹
            st.subheader("é‡å¤é¡¹å¤„ç†")
            handle_duplicates = st.radio(
                "å¦‚ä½•å¤„ç†ç‰©æµå•å·è¡¨ä¸­çš„é‡å¤æ”¶ä»¶äººè®°å½•",
                ["ä¿ç•™ç¬¬ä¸€æ¡è®°å½•", "åˆå¹¶æ‰€æœ‰è®°å½•ï¼ˆå¯èƒ½å¯¼è‡´è¡Œæ•°å¢åŠ ï¼‰"],
                index=0,
                key="handle_duplicates"
            )
            
            # é€‰æ‹©è¾“å‡ºåˆ—
            st.subheader("è¾“å‡ºåˆ—é€‰æ‹©")
            with st.expander("ç‚¹å‡»é€‰æ‹©è¾“å‡ºåˆ—", expanded=True):
                # å®šä¹‰å…³é”®åˆ—
                key_columns = ['ç½‘åº—è®¢å•å·', 'æ”¶è´§äºº', 'æ‰‹æœº', 'æ”¶è´§åœ°å€', 'è´§å“åç§°', 'è§„æ ¼', 'æ•°é‡', 'ç‰©æµå…¬å¸', 'ç‰©æµå•å·', 'é¢å¤–ç‰©æµå•å·', 'å‘è´§æ—¶é—´']
                
                # åˆå¹¶åçš„æ‰€æœ‰å¯èƒ½åˆ—
                all_possible_columns = list(pending_shipment_df.columns) + columns_to_add
                
                # ç¡®ä¿å…³é”®åˆ—ä¼˜å…ˆæ˜¾ç¤º
                ordered_columns = []
                # å…ˆæ·»åŠ å…³é”®åˆ—ä¸­å­˜åœ¨äºæ•°æ®ä¸­çš„åˆ—
                for col in key_columns:
                    if col in all_possible_columns and col not in ordered_columns:
                        ordered_columns.append(col)
                
                # å†æ·»åŠ å…¶ä»–åˆ—
                for col in all_possible_columns:
                    if col not in ordered_columns:
                        ordered_columns.append(col)
                
                # é»˜è®¤é€‰ä¸­æ‰€æœ‰å…³é”®åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰åŠ ä¸Šä»ç‰©æµè¡¨æ·»åŠ çš„åˆ—
                default_output_columns = []
                for col in key_columns:
                    if col in all_possible_columns:
                        default_output_columns.append(col)
                
                # æ·»åŠ ä»ç‰©æµå•å·è¡¨ä¸­é€‰æ‹©çš„åˆ—ï¼ˆå¦‚æœå°šæœªåŒ…å«ï¼‰
                for col in columns_to_add:
                    if col not in default_output_columns:
                        default_output_columns.append(col)
                
                output_columns = st.multiselect(
                    "é€‰æ‹©æœ€ç»ˆè¾“å‡ºçš„åˆ—ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
                    ordered_columns,
                    default=default_output_columns,
                    key="output_columns"
                )
            
            if st.button("æ‰§è¡ŒåŒ¹é…"):
                if columns_to_add:
                    with st.spinner("æ­£åœ¨æ‰§è¡ŒåŒ¹é…..."):
                        try:
                            # å¤„ç†ç‰©æµå•å·è¡¨ä¸­çš„é‡å¤è®°å½•
                            if handle_duplicates == "ä¿ç•™ç¬¬ä¸€æ¡è®°å½•":
                                # å¯¹äºæ¯ä¸ªæ”¶ä»¶äººï¼Œåªä¿ç•™ç¬¬ä¸€æ¡è®°å½•
                                logistics_df_unique = logistics_df.drop_duplicates(subset=[logistics_name_select], keep='first')
                            else:
                                logistics_df_unique = logistics_df
                            
                            # æ•°æ®é¢„å¤„ç†ï¼šå»é™¤æ”¶è´§äººå§“åä¸­çš„å¤šä½™ç©ºæ ¼ï¼ˆåŒ…æ‹¬å‰å¯¼ã€å°¾éšå’Œä¸­é—´çš„å¤šä½™ç©ºæ ¼ï¼‰
                            pending_shipment_df[pending_name_select] = pending_shipment_df[pending_name_select].astype(str).str.strip().str.replace(r'\s+', ' ', regex=True)
                            logistics_df_unique[logistics_name_select] = logistics_df_unique[logistics_name_select].astype(str).str.strip().str.replace(r'\s+', ' ', regex=True)
                            
                            # æ£€æŸ¥é‡å¤åŒ¹é…æƒ…å†µ
                            pending_counts = pending_shipment_df[pending_name_select].value_counts().reset_index()
                            pending_counts.columns = [pending_name_select, 'pending_count']
                            
                            logistics_counts = logistics_df_unique[logistics_name_select].value_counts().reset_index()
                            logistics_counts.columns = [logistics_name_select, 'logistics_count']
                            
                            # åˆå¹¶è®¡æ•°ä¿¡æ¯
                            if pending_name_select == logistics_name_select:
                                count_info = pd.merge(pending_counts, logistics_counts, on=pending_name_select, how='outer').fillna(0)
                            else:
                                count_info = pd.merge(pending_counts, logistics_counts, left_on=pending_name_select, right_on=logistics_name_select, how='outer').fillna(0)
                            
                            count_info['pending_count'] = count_info['pending_count'].astype(int)
                            count_info['logistics_count'] = count_info['logistics_count'].astype(int)
                            
                            # æ˜¾ç¤ºé‡å¤æ•°æ®ç»Ÿè®¡
                            mismatched_data = count_info[(count_info['pending_count'] > 1) | (count_info['logistics_count'] > 1)]
                            if not mismatched_data.empty:
                                with st.expander("æŸ¥çœ‹é‡å¤åŒ¹é…æ•°æ®ç»Ÿè®¡"):
                                    st.info("æ£€æµ‹åˆ°é‡å¤åŒ¹é…æ•°æ®ï¼Œå»ºè®®å¯ç”¨é¡ºåºåŒ¹é…åŠŸèƒ½ä»¥è·å¾—æ›´å¥½çš„åŒ¹é…ç»“æœ")
                                    st.dataframe(mismatched_data)
                            
                            # æ£€æŸ¥æ˜¯å¦å¯ç”¨é¡ºåºåŒ¹é…
                            use_sequential_matching = st.checkbox("å¯ç”¨é¡ºåºåŒ¹é…ï¼ˆå¤„ç†å¤šå¯¹å¤šæƒ…å†µï¼‰", value=False, key="sequential_matching")
                            if use_sequential_matching and not mismatched_data.empty:
                                st.info("å·²å¯ç”¨é¡ºåºåŒ¹é…ï¼Œå°†æŒ‰é¡ºåºåŒ¹é…é‡å¤æ•°æ®")
                            
                            # ä¸ºäº†é¿å…é‡å¤åˆ—åï¼Œæˆ‘ä»¬å…ˆä»ä¸»è¡¨ä¸­ç§»é™¤ä¸ç‰©æµè¡¨åŒåçš„åˆ—ï¼ˆé™¤äº†åŒ¹é…é”®ï¼‰
                            pending_shipment_for_merge = pending_shipment_df.copy()
                            for col in columns_to_add:
                                if col in pending_shipment_for_merge.columns and col != pending_name_select:
                                    pending_shipment_for_merge = pending_shipment_for_merge.drop(columns=[col])
                            
                            if use_sequential_matching:
                                # å®ç°é¡ºåºåŒ¹é…é€»è¾‘
                                result_df = pending_shipment_for_merge.copy()
                                
                                # ä¸ºæ¯ä¸ªæ•°æ®æ¡†æ·»åŠ è¡Œå·ï¼Œç”¨äºé¡ºåºåŒ¹é…
                                result_df['_pending_row_num'] = range(len(result_df))
                                
                                merge_columns = [logistics_name_select] + columns_to_add
                                logistics_with_row_num = logistics_df_unique[merge_columns].copy()
                                logistics_with_row_num['_logistics_row_num'] = range(len(logistics_with_row_num))
                                
                                # ä¸ºæ¯ä¸ªæ”¶è´§äººæ·»åŠ åºå·
                                result_df['_pending_seq'] = result_df.groupby(pending_name_select).cumcount()
                                logistics_with_row_num['_logistics_seq'] = logistics_with_row_num.groupby(logistics_name_select).cumcount()
                                
                                # æ‰§è¡Œé¡ºåºåŒ¹é…
                                if pending_name_select == logistics_name_select:
                                    result_df = pd.merge(
                                        result_df,
                                        logistics_with_row_num,
                                        left_on=[pending_name_select, '_pending_seq'],
                                        right_on=[logistics_name_select, '_logistics_seq'],
                                        how='left',
                                        sort=False
                                    )
                                else:
                                    result_df = pd.merge(
                                        result_df,
                                        logistics_with_row_num,
                                        left_on=[pending_name_select, '_pending_seq'],
                                        right_on=[logistics_name_select, '_logistics_seq'],
                                        how='left',
                                        sort=False
                                    )
                                
                                # å¤„ç†åŒ¹é…åˆ—é‡å¤çš„é—®é¢˜
                                if pending_name_select == logistics_name_select and f"{logistics_name_select}_x" in result_df.columns:
                                    result_df = result_df.drop(columns=[f"{logistics_name_select}_y"]).rename(columns={f"{logistics_name_select}_x": logistics_name_select})
                                
                                # æ¸…ç†ä¸´æ—¶åˆ—
                                result_df = result_df.drop(columns=['_pending_row_num', '_logistics_row_num', '_pending_seq', '_logistics_seq'])
                            else:
                                # ä½¿ç”¨æ”¶ä»¶äººä½œä¸ºåŒ¹é…é”®
                                merge_columns = [logistics_name_select] + columns_to_add
                                
                                result_df = pd.merge(
                                    pending_shipment_for_merge,
                                    logistics_df_unique[merge_columns],
                                    left_on=pending_name_select,
                                    right_on=logistics_name_select,
                                    how='left',
                                    sort=False
                                )
                                
                                # å¤„ç†åŒ¹é…åˆ—é‡å¤çš„é—®é¢˜
                                if pending_name_select == logistics_name_select and f"{logistics_name_select}_x" in result_df.columns:
                                    result_df = result_df.drop(columns=[f"{logistics_name_select}_y"]).rename(columns={f"{logistics_name_select}_x": logistics_name_select})
                            
                            # ç¡®ä¿ç»“æœDataFrameçš„æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                            for col in result_df.columns:
                                result_df[col] = result_df[col].astype(str)
                            
                            # æ˜¾ç¤ºåŒ¹é…ç»Ÿè®¡ä¿¡æ¯
                            matched_count = 0
                            if columns_to_add:
                                # æ£€æŸ¥ç¬¬ä¸€åˆ—æ˜¯å¦å­˜åœ¨äºç»“æœä¸­
                                first_column = columns_to_add[0]
                                if first_column in result_df.columns:
                                    matched_count = result_df[first_column].notna().sum()
                                else:
                                    # å¦‚æœç¬¬ä¸€åˆ—ä¸å­˜åœ¨ï¼Œæ£€æŸ¥å…¶ä»–åˆ—
                                    for col in columns_to_add:
                                        if col in result_df.columns:
                                            matched_count = result_df[col].notna().sum()
                                            break
                            st.info(f"æˆåŠŸåŒ¹é… {matched_count} æ¡è®°å½•")
                            
                            # åªä¿ç•™æŒ‡å®šçš„è¾“å‡ºåˆ—
                            if output_columns:
                                # æ£€æŸ¥é€‰å®šçš„åˆ—æ˜¯å¦å­˜åœ¨äºç»“æœä¸­
                                existing_output_columns = [col for col in output_columns if col in result_df.columns]
                                result_df = result_df[existing_output_columns]
                            
                            st.success("åŒ¹é…å®Œæˆï¼")
                            st.subheader("åŒ¹é…ç»“æœç»Ÿè®¡")
                            st.write(f"åŸå§‹å¾…å‘è´§æ˜ç»†è¡¨è¡Œæ•°: {len(pending_shipment_df)}")
                            st.write(f"åŒ¹é…åç»“æœè¡Œæ•°: {len(result_df)}")
                            
                            if len(result_df) > len(pending_shipment_df):
                                st.warning("æ³¨æ„ï¼šç»“æœè¡Œæ•°å¢åŠ ï¼Œè¿™æ˜¯å› ä¸ºæŸäº›æ”¶ä»¶äººåœ¨ç‰©æµå•å·è¡¨ä¸­æœ‰å¤šæ¡è®°å½•")
                            
                            st.subheader("åŒ¹é…ç»“æœé¢„è§ˆ")
                            st.dataframe(result_df.head(20))
                            
                            # æä¾›ä¸‹è½½
                            output_file = f"å‘è´§æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            result_df.to_excel(output_file, index=False)
                            
                            with open(output_file, "rb") as file:
                                st.download_button(
                                    label="ä¸‹è½½åŒ¹é…ç»“æœ",
                                    data=file,
                                    file_name=output_file,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        except Exception as e:
                            st.error(f"åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                            import traceback
                            st.error(traceback.format_exc())
                else:
                    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—æ·»åŠ åˆ°å¾…å‘è´§æ˜ç»†è¡¨ä¸­")
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

# æ·»åŠ æ–°çš„åŠŸèƒ½æ¨¡å—
elif app_mode == "å•†å“æ•°é‡è½¬æ¢":
    st.header("å•†å“æ•°é‡è½¬æ¢")
    st.info("æ­¤åŠŸèƒ½æ”¯æŒåŒå‘è½¬æ¢ï¼šç®±â†”ä¸ªï¼Œæ‚¨å¯ä»¥é€‰æ‹©è½¬æ¢æ–¹å‘å’Œè¦è½¬æ¢çš„å•†å“")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ å‘è´§æ˜ç»†æ–‡ä»¶", type=["xlsx"], key="convert_quantities")

    if uploaded_file:
        try:
            # è¯»å–æ–‡ä»¶
            df = pd.read_excel(uploaded_file)

            st.subheader("åŸå§‹æ•°æ®é¢„è§ˆ")
            st.dataframe(df.head(10))

            # é€‰æ‹©å¿…è¦çš„åˆ—
            col1, col2, col3 = st.columns(3)
            with col1:
                if 'è´§å“åç§°' in df.columns:
                    product_col = 'è´§å“åç§°'
                elif 'äº§å“åç§°' in df.columns:
                    product_col = 'äº§å“åç§°'
                else:
                    product_col = st.selectbox("é€‰æ‹©åŒ…å«äº§å“åç§°çš„åˆ—", df.columns)

            with col2:
                if 'æ•°é‡' in df.columns:
                    quantity_col = 'æ•°é‡'
                else:
                    quantity_col = st.selectbox("é€‰æ‹©åŒ…å«æ•°é‡çš„åˆ—", df.columns)

            with col3:
                if 'è§„æ ¼' in df.columns:
                    unit_col = 'è§„æ ¼'
                else:
                    unit_col = st.selectbox("é€‰æ‹©åŒ…å«è§„æ ¼çš„åˆ—", df.columns)

            # å®šä¹‰è½¬æ¢è§„åˆ™ - æ”¯æŒåŒå‘è½¬æ¢
            conversion_rules = {
                "å››ç›’è£…ç¿»ç›–å¼ç¤¼ç›’": 30,  # 30ä¸ª/ç®±
                "ç›’è£…æŠ½çº¸": 20,  # 20ä¸ªï¼ˆç›’ï¼‰/ç®±
                "å¤©å¶åæ¯«å…‹": 100,  # 100ä¸ª/ç®±
                "æŠ½çº¸": 20,  # 20ä¸ªï¼ˆç›’ï¼‰/ç®±
                "ç¯ä¿å¡‘æ–™è¢‹": 300,  # 300ä¸ª/ç®±
                "ä¸¤ç›’è£…ç¿»ç›–å¼ç¤¼ç›’": 30,  # 30ä¸ª/ç®±
                "æ¹¿çº¸å·¾": 50,  # 50ä¸ªï¼ˆåŒ…ï¼‰/ç®±
                "å››ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¤©å¶å“ç³»ï¼‰": 50,  # 50ä¸ª/ç®±
                "äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¸¸è§„æ¬¾ï¼‰": 50,  # 50ä¸ª/ç®±
                "äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆç»†æ”¯æ¬¾ï¼‰": 50,  # 50ä¸ª/ç®±
                "äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆä¸­æ”¯æ¬¾ï¼‰": 50,  # 50ä¸ª/ç®±
                "é™¤è¨ä»ª": 1,  # å•ä¸ªå•†å“ï¼Œä¸éœ€è¦è½¬æ¢å€æ•°
                "æ•°æ®çº¿ä¸‰åˆä¸€å……ç”µçº¿100W": 1,  # å•ä¸ªå•†å“
                "å‰ƒé¡»åˆ€ä¾¿æºåˆé‡‘ç”µåŠ¨åˆ®èƒ¡åˆ€ç”·å£«": 1  # å•ä¸ªå•†å“
            }

            # è½¬æ¢æ–¹å‘é€‰æ‹©
            st.subheader("è½¬æ¢è®¾ç½®")
            col1, col2 = st.columns(2)
            
            with col1:
                conversion_direction = st.radio(
                    "é€‰æ‹©è½¬æ¢æ–¹å‘",
                    ["ç®± â†’ ä¸ª", "ä¸ª â†’ ç®±"],
                    help="ç®±â†’ä¸ªï¼šå°†ç®±è£…æ•°é‡è½¬æ¢ä¸ºä¸ªè£…æ•°é‡\nä¸ªâ†’ç®±ï¼šå°†ä¸ªè£…æ•°é‡è½¬æ¢ä¸ºç®±è£…æ•°é‡"
                )
            
            with col2:
                # æ˜¾ç¤ºå½“å‰æ–‡ä»¶ä¸­çš„è§„æ ¼ä¿¡æ¯
                unique_units = df[unit_col].unique()
                st.write("å½“å‰æ–‡ä»¶ä¸­çš„è§„æ ¼:")
                st.write(unique_units.tolist())

            # å•†å“é€‰æ‹©åŠŸèƒ½
            st.subheader("å•†å“é€‰æ‹©")
            
            # è·å–å½“å‰æ–‡ä»¶ä¸­æ‰€æœ‰å•†å“
            unique_products = df[product_col].unique()
            unique_products = [str(p) for p in unique_products if pd.notna(p) and str(p).strip()]
            
            # ç­›é€‰å‡ºæœ‰è½¬æ¢è§„åˆ™çš„å•†å“
            products_with_rules = []
            for product in unique_products:
                for keyword in conversion_rules.items():
                    if (keyword[0] == product or
                        product.startswith(keyword[0]) or
                        product.endswith(keyword[0]) or
                        keyword[0] in product):
                        products_with_rules.append(product)
                        break
            
            products_with_rules = list(set(products_with_rules))  # å»é‡
            
            if products_with_rules:
                # å•†å“å¤šé€‰
                selected_products = st.multiselect(
                    f"é€‰æ‹©è¦è½¬æ¢çš„å•†å“ï¼ˆå…±{len(products_with_rules)}ä¸ªå¯è½¬æ¢å•†å“ï¼‰",
                    products_with_rules,
                    default=products_with_rules,  # é»˜è®¤å…¨é€‰
                    key="selected_products"
                )
                
                st.info(f"å·²é€‰æ‹© {len(selected_products)} ä¸ªå•†å“è¿›è¡Œè½¬æ¢")
                
                # æ˜¾ç¤ºé€‰ä¸­å•†å“çš„è½¬æ¢è§„åˆ™
                if selected_products:
                    st.subheader("é€‰ä¸­å•†å“çš„è½¬æ¢è§„åˆ™")
                    rule_info = []
                    for product in selected_products:
                        # æ£€æŸ¥å•†å“æ˜¯å¦éœ€è¦è½¬æ¢ï¼ˆæ ¹æ®è§„æ ¼ï¼‰
                        product_data = df[df[product_col] == product]
                        needs_box_to_individual = False
                        needs_individual_to_box = False
                        
                        # æ£€æŸ¥è¯¥å•†å“çš„è§„æ ¼
                        for _, row in product_data.iterrows():
                            unit_str = str(row[unit_col])
                            if 'ç®±' in unit_str and 'ä¸ª' not in unit_str:
                                needs_box_to_individual = True
                            elif ('ä¸ª' in unit_str or 'å°' in unit_str or 'æ¡' in unit_str or 'åŒ…' in unit_str) and 'ç®±' not in unit_str:
                                needs_individual_to_box = True
                        
                        for keyword, multiplier in conversion_rules.items():
                            if (keyword == product or
                                product.startswith(keyword) or
                                product.endswith(keyword) or
                                keyword in product):
                                # æ ¹æ®è½¬æ¢æ–¹å‘å’Œå®é™…è§„æ ¼æ˜¾ç¤ºè§„åˆ™
                                if conversion_direction == "ç®± â†’ ä¸ª":
                                    if needs_box_to_individual:
                                        rule_info.append(f"{product}: 1ç®± = {multiplier}ä¸ª")
                                    else:
                                        rule_info.append(f"{product}: æ— éœ€è½¬æ¢ï¼ˆè§„æ ¼å·²ä¸ºä¸ªæˆ–éç®±ï¼‰")
                                else:  # ä¸ª â†’ ç®±
                                    if needs_individual_to_box:
                                        rule_info.append(f"{product}: {multiplier}ä¸ª = 1ç®±")
                                    else:
                                        rule_info.append(f"{product}: æ— éœ€è½¬æ¢ï¼ˆè§„æ ¼å·²ä¸ºç®±æˆ–éä¸ªï¼‰")
                                break
                    
                    for info in rule_info:
                        st.write(f"â€¢ {info}")
            else:
                st.warning("æœªæ‰¾åˆ°å¯è½¬æ¢çš„å•†å“ï¼Œè¯·æ£€æŸ¥å•†å“åç§°æ˜¯å¦åŒ…å«ä»¥ä¸‹å…³é”®è¯ï¼š")
                st.write(list(conversion_rules.keys()))
                selected_products = []

            # è½¬æ¢é¢„è§ˆ
            if selected_products:
                st.subheader("è½¬æ¢é¢„è§ˆ")
                
                # ç­›é€‰å‡ºé€‰ä¸­å•†å“çš„æ•°æ®
                preview_df = df[df[product_col].isin(selected_products)].copy()
                
                if not preview_df.empty:
                    # è®¡ç®—è½¬æ¢åçš„æ•°é‡
                    preview_df['è½¬æ¢åæ•°é‡'] = preview_df[quantity_col].copy()
                    
                    for index, row in preview_df.iterrows():
                        product_name = str(row[product_col])
                        original_quantity = float(row[quantity_col]) if pd.notna(row[quantity_col]) else 0
                        
                        # æŸ¥æ‰¾åŒ¹é…çš„è½¬æ¢è§„åˆ™
                        multiplier = None
                        for keyword, mult in conversion_rules.items():
                            if (keyword == product_name or
                                product_name.startswith(keyword) or
                                product_name.endswith(keyword) or
                                keyword in product_name):
                                multiplier = mult
                                break
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
                        need_convert = False
                        if conversion_direction == "ç®± â†’ ä¸ª":
                            if 'ç®±' in str(row[unit_col]) and 'ä¸ª' not in str(row[unit_col]):
                                need_convert = True
                        elif conversion_direction == "ä¸ª â†’ ç®±":
                            unit_str = str(row[unit_col])
                            if ('ä¸ª' in unit_str or 'å°' in unit_str or 'æ¡' in unit_str or 'åŒ…' in unit_str) and 'ç®±' not in unit_str:
                                need_convert = True
                        
                        if multiplier and multiplier > 1 and need_convert:
                            if conversion_direction == "ç®± â†’ ä¸ª":
                                converted_quantity = original_quantity * multiplier
                            else:  # ä¸ª â†’ ç®±
                                converted_quantity = original_quantity / multiplier
                            preview_df.at[index, 'è½¬æ¢åæ•°é‡'] = converted_quantity
                    
                    # æ˜¾ç¤ºé¢„è§ˆï¼ˆåªæ˜¾ç¤ºç›¸å…³åˆ—ï¼‰
                    preview_columns = [product_col, quantity_col, unit_col, 'è½¬æ¢åæ•°é‡']
                    if 'æ”¶è´§äºº' in preview_df.columns:
                        preview_columns.insert(0, 'æ”¶è´§äºº')
                    
                    st.dataframe(preview_df[preview_columns].head(10))
                    
                    # ç»Ÿè®¡ä¿¡æ¯
                    total_original = preview_df[quantity_col].sum()
                    total_converted = preview_df['è½¬æ¢åæ•°é‡'].sum()
                    st.info(f"è½¬æ¢ç»Ÿè®¡ï¼šåŸå§‹æ€»æ•° {total_original}ï¼Œè½¬æ¢åæ€»æ•° {total_converted:.2f}")

            # æ‰§è¡Œè½¬æ¢æŒ‰é’®
            if selected_products and st.button("æ‰§è¡Œæ•°é‡è½¬æ¢"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œå•†å“æ•°é‡è½¬æ¢..."):
                    # åˆ›å»ºç»“æœDataFrameçš„å‰¯æœ¬
                    result_df = df.copy()
                    
                    # æ ¹æ®è½¬æ¢æ–¹å‘æ·»åŠ æ–°åˆ—
                    if conversion_direction == "ç®± â†’ ä¸ª":
                        new_column_name = 'æ•°é‡ï¼ˆä¸ªï¼‰'
                        new_unit_name = 'ä¸ª'
                    else:  # ä¸ª â†’ ç®±
                        new_column_name = 'æ•°é‡ï¼ˆç®±ï¼‰'
                        new_unit_name = 'ç®±'
                    
                    # æ‰¾åˆ°æ•°é‡åˆ—çš„ä½ç½®
                    quantity_col_index = list(result_df.columns).index(quantity_col)
                    
                    # åˆ›å»ºæ–°åˆ—æ•°æ®
                    new_column_data = pd.to_numeric(result_df[quantity_col], errors='coerce').fillna(0)
                    new_unit_data = result_df[unit_col].copy()
                    
                    # å°†æ–°åˆ—æ’å…¥åˆ°æ•°é‡åˆ—åé¢
                    columns_list = list(result_df.columns)
                    columns_list.insert(quantity_col_index + 1, new_column_name)
                    columns_list.insert(quantity_col_index + 2, 'è§„æ ¼ï¼ˆè½¬æ¢åï¼‰')
                    
                    # é‡æ–°æ’åˆ—DataFrameçš„åˆ—
                    result_df = result_df.reindex(columns=columns_list)
                    
                    # å¡«å……æ–°åˆ—æ•°æ®
                    result_df[new_column_name] = new_column_data
                    result_df['è§„æ ¼ï¼ˆè½¬æ¢åï¼‰'] = new_unit_data
                    
                    # æ‰§è¡Œè½¬æ¢
                    converted_count = 0
                    for index, row in result_df.iterrows():
                        product_name = str(row[product_col])

                        # åªè½¬æ¢é€‰ä¸­çš„å•†å“
                        if product_name in selected_products:
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢ï¼ˆæ ¹æ®è½¬æ¢æ–¹å‘å’Œè§„æ ¼åˆ¤æ–­ï¼‰
                            need_convert = False
                            if conversion_direction == "ç®± â†’ ä¸ª":
                                # åªæœ‰è§„æ ¼ä¸º"ç®±"çš„æ‰éœ€è¦è½¬æ¢
                                if 'ç®±' in str(row[unit_col]) and 'ä¸ª' not in str(row[unit_col]):
                                    need_convert = True
                            elif conversion_direction == "ä¸ª â†’ ç®±":
                                # åªæœ‰è§„æ ¼ä¸º"ä¸ª"ã€"å°"ã€"æ¡"ã€"åŒ…"ç­‰çš„æ‰éœ€è¦è½¬æ¢
                                unit_str = str(row[unit_col])
                                if ('ä¸ª' in unit_str or 'å°' in unit_str or 'æ¡' in unit_str or 'åŒ…' in unit_str) and 'ç®±' not in unit_str:
                                    need_convert = True
                            
                            if need_convert:
                                # æŸ¥æ‰¾åŒ¹é…çš„è½¬æ¢è§„åˆ™
                                multiplier = None
                                for keyword, mult in conversion_rules.items():
                                    if (keyword == product_name or
                                        product_name.startswith(keyword) or
                                        product_name.endswith(keyword) or
                                        keyword in product_name):
                                        multiplier = mult
                                        break
                                
                                if multiplier and multiplier > 1:
                                    try:
                                        original_quantity = float(row[quantity_col])
                                        if conversion_direction == "ç®± â†’ ä¸ª":
                                            converted_quantity = original_quantity * multiplier
                                        else:  # ä¸ª â†’ ç®±
                                            converted_quantity = original_quantity / multiplier
                                        
                                        result_df.at[index, new_column_name] = converted_quantity
                                        result_df.at[index, 'è§„æ ¼ï¼ˆè½¬æ¢åï¼‰'] = new_unit_name
                                        converted_count += 1
                                    except (ValueError, TypeError):
                                        pass

                    # æ˜¾ç¤ºè½¬æ¢ç»“æœ
                    st.success(f"å•†å“æ•°é‡è½¬æ¢å®Œæˆï¼å…±è½¬æ¢äº† {converted_count} æ¡è®°å½•")

                    # æ˜¾ç¤ºè½¬æ¢åçš„æ•°æ®é¢„è§ˆ
                    st.subheader("è½¬æ¢åæ•°æ®é¢„è§ˆ")

                    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
                    preview_columns = [product_col, quantity_col, unit_col, new_column_name, 'è§„æ ¼ï¼ˆè½¬æ¢åï¼‰']
                    if 'æ”¶è´§äºº' in result_df.columns:
                        preview_columns.insert(0, 'æ”¶è´§äºº')
                    
                    # åªæ˜¾ç¤ºæœ‰è½¬æ¢çš„è®°å½•
                    # ä½¿ç”¨numpyæ•°ç»„æ¯”è¾ƒæ¥é¿å…ç´¢å¼•å¯¹é½é—®é¢˜
                    converted_mask = result_df[new_column_name].values != result_df[quantity_col].values
                    converted_df = result_df[converted_mask]
                    if not converted_df.empty:
                        st.write("å·²è½¬æ¢çš„è®°å½•ï¼š")
                        st.dataframe(converted_df[preview_columns].head(20))
                    else:
                        st.info("æ²¡æœ‰è®°å½•è¢«è½¬æ¢ï¼Œè¯·æ£€æŸ¥é€‰æ‹©çš„æ¡ä»¶")

                    # æä¾›ä¸‹è½½
                    output_file = f"è½¬æ¢åå‘è´§æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    result_df.to_excel(output_file, index=False)

                    with open(output_file, "rb") as file:
                        st.download_button(
                            label="ä¸‹è½½è½¬æ¢ç»“æœ",
                            data=file,
                            file_name=output_file,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
            elif not selected_products:
                st.warning("è¯·å…ˆé€‰æ‹©è¦è½¬æ¢çš„å•†å“")

        except Exception as e:
            st.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

elif app_mode == "è¡¨åˆå¹¶":
    st.header("è¡¨åˆå¹¶")
    st.info("æ­¤åŠŸèƒ½å°†çºµå‘åˆå¹¶å¤šä¸ªè¡¨æ ¼ï¼Œå¹¶è‡ªåŠ¨ç§»é™¤å…¨ç©ºçš„åˆ—")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ éœ€è¦åˆå¹¶çš„Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
        type=["xlsx"],
        accept_multiple_files=True,
        key="merge_files"
    )
    
    if uploaded_files and len(uploaded_files) >= 2:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        if st.button("æ‰§è¡Œåˆå¹¶"):
            with st.spinner("æ­£åœ¨æ‰§è¡Œåˆå¹¶..."):
                try:
                    # è¯»å–æ‰€æœ‰æ–‡ä»¶
                    dataframes = []
                    for uploaded_file in uploaded_files:
                        df = pd.read_excel(uploaded_file)
                        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
                        for col in df.columns:
                            df[col] = df[col].astype(str)
                        dataframes.append(df)
                    
                    # çºµå‘åˆå¹¶æ‰€æœ‰è¡¨æ ¼
                    result_df = pd.concat(dataframes, ignore_index=True)
                    
                    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    for col in result_df.columns:
                        result_df[col] = result_df[col].astype(str)
                    
                    # è‡ªåŠ¨è¿‡æ»¤å…¨ç©ºçš„åˆ—
                    columns_to_keep = []
                    for col in result_df.columns:
                        # æ£€æŸ¥åˆ—æ˜¯å¦å…¨ä¸ºç©ºå€¼ï¼ˆé™¤äº†æ ‡é¢˜ï¼‰
                        non_empty_values = result_df[col][result_df[col].notna() & (result_df[col] != '') & (result_df[col] != 'nan')]
                        if len(non_empty_values) > 0:
                            columns_to_keep.append(col)
                    
                    # åªä¿ç•™éç©ºåˆ—
                    result_df = result_df[columns_to_keep]
                    
                    st.success("åˆå¹¶å®Œæˆï¼")
                    st.write(f"åˆå¹¶åæ€»è¡Œæ•°: {len(result_df)}ï¼Œæ€»åˆ—æ•°: {len(result_df.columns)}")
                    
                    st.subheader("åˆå¹¶ç»“æœé¢„è§ˆ")
                    st.dataframe(result_df.head(20))
                    
                    # æä¾›ä¸‹è½½
                    output_file = f"åˆå¹¶ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    result_df.to_excel(output_file, index=False)
                    
                    with open(output_file, "rb") as file:
                        st.download_button(
                            label="ä¸‹è½½åˆå¹¶ç»“æœ",
                            data=file,
                            file_name=output_file,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                except Exception as e:
                    st.error(f"åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                    import traceback
                    st.error(traceback.format_exc())
    else:
        st.info("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶è¿›è¡Œåˆå¹¶")
# elif app_mode == "ç®€åŒ–è¡¨åˆå¹¶":
#     st.header("ç®€åŒ–è¡¨åˆå¹¶")
#     st.info("æ­¤åŠŸèƒ½å°†çºµå‘åˆå¹¶å¤šä¸ªè¡¨æ ¼ï¼Œå¹¶è‡ªåŠ¨ç§»é™¤å…¨ç©ºçš„åˆ—")
#
#     # æ–‡ä»¶ä¸Šä¼ 
#     uploaded_files = st.file_uploader(
#         "ä¸Šä¼ éœ€è¦åˆå¹¶çš„Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
#         type=["xlsx"],
#         accept_multiple_files=True,
#         key="simple_merge_files"
#     )
#
#     if uploaded_files and len(uploaded_files) >= 2:
#         st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
#
#         # æ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶å
#         file_names = [f.name for f in uploaded_files]
#         st.write("ä¸Šä¼ çš„æ–‡ä»¶:")
#         for i, name in enumerate(file_names):
#             st.write(f"{i+1}. {name}")
#
#         try:
#             # è¯»å–æ‰€æœ‰æ–‡ä»¶
#             dataframes = []
#             for uploaded_file in uploaded_files:
#                 df = pd.read_excel(uploaded_file)
#                 # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
#                 for col in df.columns:
#                     df[col] = df[col].astype(str)
#                 dataframes.append(df)
#
#             st.subheader("æ–‡ä»¶é¢„è§ˆ")
#             tabs = st.tabs([f"è¡¨{i+1}" for i in range(len(dataframes))])
#             for i, (tab, df) in enumerate(zip(tabs, dataframes)):
#                 with tab:
#                     st.write(f"è¡¨{i+1} ({file_names[i]}) åˆ—å:")
#                     st.write(list(df.columns))
#                     st.write(f"å‰5è¡Œæ•°æ®:")
#                     st.dataframe(df.head(5))
#
#             if st.button("æ‰§è¡Œåˆå¹¶"):
#                 with st.spinner("æ­£åœ¨æ‰§è¡Œåˆå¹¶..."):
#                     try:
#                         # çºµå‘åˆå¹¶æ‰€æœ‰è¡¨æ ¼
#                         result_df = pd.concat(dataframes, ignore_index=True)
#
#                         # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
#                         for col in result_df.columns:
#                             result_df[col] = result_df[col].astype(str)
#
#                         st.write(f"åˆå¹¶åæ€»è¡Œæ•°: {len(result_df)}")
#
#                         # æ˜¾ç¤ºæ‰€æœ‰åˆ—å
#                         st.write("æ‰€æœ‰åˆ—å:")
#                         all_columns = list(result_df.columns)
#                         st.write(all_columns)
#
#                         # è‡ªåŠ¨è¿‡æ»¤å…¨ç©ºçš„åˆ—
#                         columns_to_keep = []
#                         for col in result_df.columns:
#                             # æ£€æŸ¥åˆ—æ˜¯å¦å…¨ä¸ºç©ºå€¼ï¼ˆé™¤äº†æ ‡é¢˜ï¼‰
#                             non_empty_values = result_df[col][result_df[col].notna() & (result_df[col] != '') & (result_df[col] != 'nan')]
#                             if len(non_empty_values) > 0:
#                                 columns_to_keep.append(col)
#
#                         st.write("éç©ºåˆ—:")
#                         st.write(columns_to_keep)
#
#                         # é€‰æ‹©è¦ä¿ç•™çš„åˆ—
#                         st.subheader("é€‰æ‹©è¦ä¿ç•™çš„åˆ—")
#                         selected_columns = st.multiselect(
#                             "é€‰æ‹©è¦ä¿ç•™çš„åˆ—ï¼ˆé»˜è®¤é€‰æ‹©æ‰€æœ‰éç©ºåˆ—ï¼‰",
#                             all_columns,
#                             default=columns_to_keep,
#                             key="selected_columns"
#                         )
#
#                         # å¦‚æœç”¨æˆ·é€‰æ‹©äº†åˆ—ï¼Œåˆ™åªä¿ç•™è¿™äº›åˆ—
#                         if selected_columns:
#                             result_df = result_df[selected_columns]
#
#                         st.success("åˆå¹¶å®Œæˆï¼")
#                         st.subheader("åˆå¹¶ç»“æœç»Ÿè®¡")
#                         st.write(f"åˆå¹¶åæ€»è¡Œæ•°: {len(result_df)}")
#                         st.write(f"åˆå¹¶åæ€»åˆ—æ•°: {len(result_df.columns)}")
#
#                         st.subheader("åˆå¹¶ç»“æœé¢„è§ˆ")
#                         st.dataframe(result_df.head(20))
#
#                         # æä¾›ä¸‹è½½
#                         output_file = f"ç®€åŒ–åˆå¹¶ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
#                         result_df.to_excel(output_file, index=False)
#
#                         with open(output_file, "rb") as file:
#                             st.download_button(
#                                 label="ä¸‹è½½åˆå¹¶ç»“æœ",
#                                 data=file,
#                                 file_name=output_file,
#                                 mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
#                             )
#                     except Exception as e:
#                         st.error(f"åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
#                         import traceback
#                         st.error(traceback.format_exc())
#         except Exception as e:
#             st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
#             import traceback
#             st.error(traceback.format_exc())
#     else:
#         st.info("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶è¿›è¡Œåˆå¹¶")

elif app_mode == "ä¾›åº”å•†è®¢å•åˆ†æ":
    st.header("ä¾›åº”å•†è®¢å•åˆ†æ")
    st.info("æ­¤åŠŸèƒ½ç”¨äºåˆ†æä¾›åº”å•†è®¢å•æ•°æ®ï¼ŒåŒ…æ‹¬äº§å“ã€ä»·æ ¼ã€æ•°é‡ã€æ€»é‡‘é¢ç­‰ç»´åº¦çš„ç»Ÿè®¡åˆ†æ")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_file = st.file_uploader("ä¸Šä¼ ä¾›åº”å•†è®¢å•æ–‡ä»¶", type=["xlsx"], key="supplier_analysis")

    if uploaded_file:
        try:
            # è¯»å–æ–‡ä»¶ï¼Œæ­£ç¡®å¤„ç†è¡¨å¤´
            df = pd.read_excel(uploaded_file, header=1)  # å‡è®¾ç¬¬äºŒè¡Œæ˜¯çœŸæ­£çš„åˆ—å

            # æ•°æ®é¢„å¤„ç†
            # å°†æ•°å€¼åˆ—è½¬æ¢ä¸ºæ­£ç¡®çš„æ•°æ®ç±»å‹
            numeric_columns = ['æ•°é‡', 'å•ä»·(å…ƒ)', 'å«ç¨æ€»é‡‘é¢(å…ƒ)']
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

            # ç¡®ä¿éæ•°å€¼åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
            for col in df.columns:
                if col not in numeric_columns:
                    df[col] = df[col].astype(str)

            # åˆ†æéƒ¨åˆ†
            st.subheader("æ•°æ®åˆ†æ")

            # 1. æ¯ä¸ªä¾›åº”å•†çš„è¯¦ç»†åˆ†æ
            required_columns = ['ä¾›åº”å•†', 'å•†å“åç§°', 'æ•°é‡', 'å«ç¨æ€»é‡‘é¢(å…ƒ)']
            if all(col in df.columns for col in required_columns):
                st.write("### å„ä¾›åº”å•†è¯¦ç»†åˆ†æ")
                suppliers = df['ä¾›åº”å•†'].unique()

                # é™åˆ¶æ˜¾ç¤ºçš„ä¾›åº”å•†æ•°é‡ï¼Œé¿å…ç•Œé¢è¿‡äºå¤æ‚
                max_suppliers = min(10, len(suppliers))
                if len(suppliers) > 10:
                    st.warning(f"ä¾›åº”å•†æ•°é‡è¾ƒå¤šï¼Œä»…æ˜¾ç¤ºå‰{max_suppliers}ä¸ªä¾›åº”å•†çš„è¯¦ç»†ä¿¡æ¯")

                # ä¸ºæ¯ä¸ªä¾›åº”å•†åˆ›å»ºä¸€ä¸ªå¯æŠ˜å åŒºåŸŸ
                for i, supplier in enumerate(suppliers[:max_suppliers]):
                    with st.expander(f"{supplier} è¯¦ç»†ä¿¡æ¯"):
                        st.write(f"##### {supplier}")
                        supplier_data = df[df['ä¾›åº”å•†'] == supplier]

                        # è¯¥ä¾›åº”å•†çš„å•†å“æ•°é‡å’Œæ€»é‡‘é¢
                        if 'å•†å“åç§°' in df.columns and 'æ•°é‡' in df.columns and 'å«ç¨æ€»é‡‘é¢(å…ƒ)' in df.columns:
                            supplier_product_summary = supplier_data.groupby('å•†å“åç§°').agg({
                                'æ•°é‡': 'sum',
                                'å«ç¨æ€»é‡‘é¢(å…ƒ)': 'sum'
                            }).sort_values('å«ç¨æ€»é‡‘é¢(å…ƒ)', ascending=False).head(15)  # é™åˆ¶æ˜¾ç¤ºå‰15ä¸ªå•†å“

                            st.write("å•†å“æ•°é‡å’Œæ€»é‡‘é¢:")
                            st.dataframe(supplier_product_summary)

                            # å¯è§†åŒ–å•†å“æ•°é‡å’Œæ€»é‡‘é¢
                            if not supplier_product_summary.empty:
                                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                                quantity_data = supplier_product_summary['æ•°é‡'].astype(float)
                                amount_data = supplier_product_summary['å«ç¨æ€»é‡‘é¢(å…ƒ)'].astype(float)

                                col1, col2 = st.columns(2)
                                with col1:
                                    st.write("å•†å“æ•°é‡åˆ†å¸ƒ:")
                                    st.bar_chart(quantity_data)
                                with col2:
                                    st.write("å•†å“æ€»é‡‘é¢åˆ†å¸ƒ:")
                                    st.bar_chart(amount_data)

                        # è¯¥ä¾›åº”å•†çš„åœ°åŒºåˆ†å¸ƒ
                        if 'çœä»½' in df.columns and 'å«ç¨æ€»é‡‘é¢(å…ƒ)' in df.columns:
                            supplier_province = supplier_data.groupby('çœä»½')['å«ç¨æ€»é‡‘é¢(å…ƒ)'].sum().sort_values(
                                ascending=False)
                            if not supplier_province.empty:
                                st.write("åœ°åŒºè®¢å•æ€»é‡‘é¢åˆ†å¸ƒ:")
                                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                                province_data = supplier_province.astype(float)
                                st.bar_chart(province_data)
                                st.dataframe(supplier_province)

            # 2. ç»¼åˆç»Ÿè®¡è¡¨
            st.write("### ç»¼åˆç»Ÿè®¡")
            if all(col in df.columns for col in ['ä¾›åº”å•†', 'å•†å“åç§°', 'æ•°é‡', 'å«ç¨æ€»é‡‘é¢(å…ƒ)']):
                summary_stats = df.groupby('ä¾›åº”å•†').agg({
                    'å«ç¨æ€»é‡‘é¢(å…ƒ)': ['sum', 'mean', 'count'],
                    'æ•°é‡': 'sum'
                }).round(2)
                summary_stats.columns = ['æ€»é‡‘é¢', 'å¹³å‡é‡‘é¢', 'è®¢å•æ•°', 'æ€»æ•°é‡']
                st.dataframe(summary_stats)

                # æ·»åŠ ç»¼åˆå›¾è¡¨
                st.write("### ç»¼åˆåˆ†æå›¾è¡¨")
                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
                total_amount_by_supplier = df.groupby('ä¾›åº”å•†')['å«ç¨æ€»é‡‘é¢(å…ƒ)'].sum().astype(float)
                total_quantity_by_supplier = df.groupby('ä¾›åº”å•†')['æ•°é‡'].sum().astype(float)

                col1, col2 = st.columns(2)
                with col1:
                    st.write("å„ä¾›åº”å•†æ€»é‡‘é¢")
                    st.bar_chart(total_amount_by_supplier)
                with col2:
                    st.write("å„ä¾›åº”å•†æ€»æ•°é‡")
                    st.bar_chart(total_quantity_by_supplier)

            st.success("åˆ†æå®Œæˆï¼")

        except Exception as e:
            st.error(f"æ•°æ®åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback

            st.error(traceback.format_exc())
    else:
        st.info("è¯·ä¸Šä¼ ä¾›åº”å•†è®¢å•æ–‡ä»¶è¿›è¡Œåˆ†æ")

# é¡µè„š
st.markdown("---")
st.markdown("Â© 2025 æ•°æ®å¤„ç†ç³»ç»Ÿ v1.0")