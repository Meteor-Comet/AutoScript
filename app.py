#http://localhost:8501/
import streamlit as st
import pandas as pd
import os
import glob
from datetime import datetime
import tempfile
import shutil

# å¯¼å…¥æ™ºèƒ½åˆ—è¯†åˆ«å‡½æ•°
from smart_column_functions import find_header_row, identify_key_columns, identify_columns_by_pattern, is_phone_number

def smart_column_detection(df, filename):
    """
    æ™ºèƒ½è¯†åˆ«è¡¨æ ¼ä¸­çš„å§“åã€è”ç³»æ–¹å¼ã€æ”¶è´§åœ°å€ç­‰ä¿¡æ¯ï¼Œä¸ä¾èµ–å›ºå®šçš„åˆ—åå’Œè¡Œå·
    """
    try:
        # ç¬¬ä¸€æ­¥ï¼šæ‰¾åˆ°çœŸæ­£çš„è¡¨å¤´è¡Œ
        header_row_idx = find_header_row(df)
        
        # å¦‚æœæ‰¾åˆ°äº†è¡¨å¤´è¡Œï¼Œé‡æ–°è®¾ç½®åˆ—å
        if header_row_idx is not None and header_row_idx > 0:
            # ä¿å­˜åŸå§‹åˆ—åä»¥å¤‡åç”¨
            original_columns = df.columns.tolist()
            # è®¾ç½®æ–°çš„åˆ—å
            df.columns = df.iloc[header_row_idx].values
            # åªä¿ç•™è¡¨å¤´è¡Œä¹‹åçš„æ•°æ®
            df = df.iloc[header_row_idx+1:].reset_index(drop=True)
        
        # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½åŒ¹é…å…³é”®åˆ—
        column_mapping = identify_key_columns(df)
        
        # ç¬¬ä¸‰æ­¥ï¼šæå–æ•°æ®
        extracted_data = []
        
        for index, row in df.iterrows():
            try:
                # åˆ›å»ºä¸€ä¸ªæ–°çš„æ•°æ®é¡¹
                item = {
                    'å®¢æˆ·åç§°': '',
                    'æ”¶è´§åœ°å€': '',
                    'æ”¶è´§äºº': '',
                    'æ‰‹æœº': '',
                    'å®¢æˆ·å¤‡æ³¨': '',  # æ–°å¢å®¢æˆ·å¤‡æ³¨å­—æ®µ
                    'æºæ–‡ä»¶': filename
                }
                
                # æ ¹æ®è¯†åˆ«çš„åˆ—æ˜ å°„å¡«å……æ•°æ®
                for target_field, source_columns in column_mapping.items():
                    for col in source_columns:
                        if col in df.columns and pd.notna(row[col]) and str(row[col]).strip():
                            item[target_field] = str(row[col]).strip()
                            break
                
                # å°†å®¢æˆ·åç§°ï¼ˆåº—åï¼‰ç§»åŠ¨åˆ°å®¢æˆ·å¤‡æ³¨å­—æ®µ
                if item['å®¢æˆ·åç§°']:
                    item['å®¢æˆ·å¤‡æ³¨'] = item['å®¢æˆ·åç§°']
                    item['å®¢æˆ·åç§°'] = ''  # æ¸…ç©ºå®¢æˆ·åç§°å­—æ®µ
                
                # åªæœ‰å½“è‡³å°‘æœ‰æ”¶è´§äººæˆ–ç”µè¯ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ æ•°æ®
                if item['æ”¶è´§äºº'] or item['æ‰‹æœº']:
                    extracted_data.append(item)
                    
            except Exception as e:
                st.warning(f"å¤„ç†ç¬¬ {index+1} è¡Œæ—¶å‡ºé”™: {e}")
        
        return extracted_data
        
    except Exception as e:
        st.error(f"æ™ºèƒ½å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {e}")
        return []

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ•°æ®å¤„ç†ç³»ç»Ÿ",
    page_icon="ğŸ§®",
    layout="wide"
)

# é¡µé¢æ ‡é¢˜
st.title("æ•°æ®å¤„ç†ç³»ç»Ÿ")
st.markdown("---")

# ä¾§è¾¹æ 
st.sidebar.header("æ“ä½œé€‰é¡¹")
app_mode = st.sidebar.selectbox(
    "é€‰æ‹©åŠŸèƒ½",
    ["æ‰¹é‡å¤„ç†å‘æ”¾æ˜ç»†", "æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•", "æ ‡è®°å‘è´§æ˜ç»†é›†é‡‡ä¿¡æ¯", "å¯¼å…¥ç›´é‚®æ˜ç»†åˆ°ä¸‰æ‹©å¯¼å•", "å¢å¼ºç‰ˆVLOOKUP", "ç‰©æµå•å·åŒ¹é…", "è¡¨åˆå¹¶"]
)

def process_å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶(file_path):
    """
    å¤„ç†å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶ï¼Œæå–æ€¡äºšé€šå…¬å¸çš„æ•°æ®
    """
    try:
        # è¯»å–Excelæ–‡ä»¶ï¼Œä¸æŒ‡å®šheaderä»¥ä¾¿æ‰‹åŠ¨å¤„ç†
        df = pd.read_excel(file_path, header=None)
        
        if df.empty:
            return pd.DataFrame()
        
        # è·å–æ ‡é¢˜è¡Œï¼ˆç¬¬ä¸€è¡Œæ˜¯æ–‡ä»¶åè¯´æ˜ï¼Œç¬¬äºŒè¡Œå¼€å§‹æ˜¯å®é™…æ ‡é¢˜ï¼‰
        header_row2 = df.iloc[1]  # ç¬¬äºŒè¡Œï¼ˆäº§å“åç§°ï¼‰
        header_row3 = df.iloc[2]  # ç¬¬ä¸‰è¡Œï¼ˆå…¬å¸åç§°ï¼‰
        
        # æ‰¾åˆ°åŒ…å«"æ€¡äºšé€š"çš„åˆ—
        yiyatong_cols = []
        for i in range(len(header_row3)):
            if pd.notna(header_row3[i]) and 'æ€¡äºšé€š' in str(header_row3[i]):
                product_name = header_row2[i] if pd.notna(header_row2[i]) else ""
                yiyatong_cols.append((i, product_name))
        
        if not yiyatong_cols:
            return pd.DataFrame()
        
        # æå–å‰14åˆ—çš„é€šç”¨ä¿¡æ¯
        info_columns = list(range(14))
        
        # æ„å»ºç»“æœæ•°æ®
        result_data = []
        
        # ä»ç¬¬4è¡Œå¼€å§‹æ˜¯æ•°æ®è¡Œï¼ˆç´¢å¼•3ï¼‰
        for row_idx in range(3, len(df)):
            row = df.iloc[row_idx]
            
            # è·³è¿‡åˆè®¡è¡Œ
            if pd.notna(row.iloc[0]) and 'åˆè®¡' in str(row.iloc[0]):
                continue
            
            # ä¸ºæ¯ä¸ªæ€¡äºšé€šäº§å“åˆ›å»ºä¸€è¡Œ
            for col_idx, product_name in yiyatong_cols:
                # æ£€æŸ¥è¯¥åˆ—çš„æ•°é‡æ˜¯å¦ä¸ä¸º0
                if col_idx < len(row) and pd.notna(row.iloc[col_idx]) and row.iloc[col_idx] != 0:
                    quantity = row.iloc[col_idx]
                    # åªæœ‰æ•°é‡ä¸ä¸º0çš„æ•°æ®æ‰æ·»åŠ 
                    if quantity != 0:
                        # è·å–é€šç”¨ä¿¡æ¯
                        base_info = []
                        for col_idx_info in info_columns:
                            if col_idx_info < len(row):
                                base_info.append(row.iloc[col_idx_info])
                            else:
                                base_info.append(None)
                        
                        # åˆ›å»ºä¸€è¡Œæ•°æ®ï¼šé€šç”¨ä¿¡æ¯(14åˆ—) + äº§å“åç§° + æ•°é‡
                        new_row = base_info + [product_name, quantity]
                        result_data.append(new_row)
        
        # æ›´æ–°åˆ—å®šä¹‰
        columns = ['åˆ¶å•æ—¥æœŸ', 'æ‰“å°æ—¶é—´', 'é¢†ç”¨å•å·', 'é¢†ç”¨ç±»å‹', 'æ–¹æ¡ˆç±»å‹', 'é¢†ç”¨éƒ¨é—¨', 
                  'åŒºåŸŸ', 'æ–¹æ¡ˆææŠ¥äºº', 'æ–¹æ¡ˆææŠ¥äººç”µè¯', 'å‘è´§ä»“åº“', 'æ”¶è´§äºº', 
                  'æ”¶è´§äººç”µè¯', 'æ”¶è´§åœ°å€', 'é¢†ç”¨è¯´æ˜', 'äº§å“åç§°', 'æ•°é‡']
        
        result_df = pd.DataFrame(result_data, columns=columns)
        return result_df
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return pd.DataFrame()

def save_with_formatting(df, filename):
    """
    ä¿å­˜DataFrameåˆ°Excelæ–‡ä»¶
    """
    df.to_excel(filename, index=False)

def batch_process_files(uploaded_files):
    """
    æ‰¹é‡å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    """
    if not uploaded_files:
        st.warning("è¯·ä¸Šä¼ è‡³å°‘ä¸€ä¸ªæ–‡ä»¶")
        return None
    
    # åˆ›å»ºä¸´æ—¶ç›®å½•æ¥ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
    with tempfile.TemporaryDirectory() as temp_dir:
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        file_paths = []
        for uploaded_file in uploaded_files:
            file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            file_paths.append(file_path)
        
        # å¤„ç†æ‰€æœ‰æ–‡ä»¶
        processed_data = []
        progress_bar = st.progress(0)
        total_files = len(file_paths)
        
        for i, file_path in enumerate(file_paths):
            progress_bar.progress((i + 1) / total_files)
            with st.spinner(f"æ­£åœ¨å¤„ç† {os.path.basename(file_path)}..."):
                df = process_å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶(file_path)
                if not df.empty:
                    processed_data.append(df)
                    st.success(f"æˆåŠŸå¤„ç† {os.path.basename(file_path)}ï¼Œæå–åˆ° {len(df)} è¡Œæ•°æ®")
        
        progress_bar.empty()
        
        # åˆå¹¶æ‰€æœ‰å¤„ç†è¿‡çš„æ•°æ®
        if processed_data:
            all_å‘æ”¾æ˜ç»† = pd.concat(processed_data, ignore_index=True)
            
            # æŒ‰åˆ¶å•æ—¥æœŸæ’åº
            if not all_å‘æ”¾æ˜ç»†.empty and 'åˆ¶å•æ—¥æœŸ' in all_å‘æ”¾æ˜ç»†.columns:
                all_å‘æ”¾æ˜ç»† = all_å‘æ”¾æ˜ç»†.sort_values('åˆ¶å•æ—¥æœŸ').reset_index(drop=True)
            
            # åªä¿ç•™å‰104è¡Œæ­£ç¡®çš„æ•°æ®
            if len(all_å‘æ”¾æ˜ç»†) > 104:
                all_å‘æ”¾æ˜ç»† = all_å‘æ”¾æ˜ç»†.iloc[:104]
            
            return all_å‘æ”¾æ˜ç»†
        else:
            st.warning("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•æ•°æ®")
            return None

def process_supplier_order_file(file_path):
    """
    å¤„ç†å•ä¸ªä¾›åº”å•†è®¢å•æŸ¥è¯¢æ–‡ä»¶
    """
    try:
        # è¯»å–Excelæ–‡ä»¶ï¼Œä¸æŒ‡å®šheaderä»¥ä¾¿æ‰‹åŠ¨å¤„ç†
        df = pd.read_excel(file_path, header=None)
        
        if df.empty:
            return None
            
        # è·å–æ ‡é¢˜è¡Œï¼ˆç¬¬äºŒè¡Œæ˜¯å®é™…çš„åˆ—æ ‡é¢˜ï¼‰
        header_row = df.iloc[1]
        
        # é‡å‘½ååˆ—
        expected_columns = ['è®¢å•ç¼–å·', 'ç¬¬ä¸‰æ–¹è®¢å•ç¼–å·', 'è®¢å•çŠ¶æ€', 'è®¢å•åˆ›å»ºæ—¶é—´', 'æ–¹æ¡ˆç¼–å·', 
                          'æ”¶è´§äºº', 'è”ç³»æ–¹å¼', 'çœä»½', 'åœ°å¸‚', 'åŒºå¿', 'æ”¶è´§åœ°å€', 
                          'å•†å“åç§°', 'æ•°é‡', 'å•ä»·(å…ƒ)', 'å•ä½', 'å«ç¨æ€»é‡‘é¢(å…ƒ)', 
                          'ä¾›åº”å•†', 'ä¸€ä»¶ä»£å‘', 'æ“ä½œ']
        
        # è·å–æ•°æ®ï¼ˆä»ç¬¬ä¸‰è¡Œå¼€å§‹ï¼‰
        data_df = df.iloc[2:].reset_index(drop=True)
        data_df.columns = expected_columns[:len(data_df.columns)]
        
        return data_df
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
        return None

def compare_data(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df):
    """
    æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•æ•°æ®
    åªæ ¸å¯¹ä¾›åº”å•†è®¢å•ä¸­å­˜åœ¨çš„è®°å½•ï¼ˆä»¥ä¾›åº”å•†è®¢å•ä¸ºå‡†ï¼‰
    åˆ†åˆ«æ ‡è¯†æ•°é‡ä¸ä¸€è‡´å’Œæ²¡æ‰¾åˆ°å¯¹åº”è®°å½•çš„æƒ…å†µ
    """
    try:
        # ç­›é€‰ä¾›åº”å•†ä¸ºæ€¡äºšé€šçš„è®¢å•
        yiyatong_orders = ä¾›åº”å•†è®¢å•_df[ä¾›åº”å•†è®¢å•_df['ä¾›åº”å•†'].str.contains('æ€¡äºšé€š', na=False)].copy()
        
        # é‡å‘½åä¾›åº”å•†è®¢å•åˆ—ä»¥ä¾¿åç»­å¤„ç†
        order_summary = yiyatong_orders[['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°', 'æ•°é‡']].copy()
        order_summary.rename(columns={'æ•°é‡': 'è®¢å•æ•°é‡'}, inplace=True)
        
        # é‡å‘½åå‘è´§æ˜ç»†åˆ—ä»¥ä¾¿åç»­å¤„ç†
        delivery_summary = å‘è´§æ˜ç»†_df[['é¢†ç”¨è¯´æ˜', 'æ”¶è´§äºº', 'äº§å“åç§°', 'æ•°é‡']].copy()
        delivery_summary.rename(columns={
            'é¢†ç”¨è¯´æ˜': 'æ–¹æ¡ˆç¼–å·',
            'äº§å“åç§°': 'å•†å“åç§°',
            'æ•°é‡': 'å‘è´§æ•°é‡'
        }, inplace=True)
        
        # æŒ‰æ–¹æ¡ˆç¼–å·ã€æ”¶è´§äººã€å•†å“åç§°åˆ†ç»„æ±‡æ€»æ•°é‡
        order_grouped = order_summary.groupby(['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°'])['è®¢å•æ•°é‡'].sum().reset_index()
        delivery_grouped = delivery_summary.groupby(['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°'])['å‘è´§æ•°é‡'].sum().reset_index()
        
        # ä»¥ä¾›åº”å•†è®¢å•ä¸ºå‡†è¿›è¡Œæ ¸å¯¹
        # å·¦è¿æ¥ç¡®ä¿æ‰€æœ‰ä¾›åº”å•†è®¢å•è®°å½•éƒ½è¢«åŒ…å«
        merged_data = pd.merge(order_grouped, delivery_grouped, on=['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'å•†å“åç§°'], how='left')
        
        # å¡«å……NaNå€¼ï¼ˆå‘è´§æ˜ç»†ä¸­æ²¡æœ‰å¯¹åº”è®°å½•çš„æƒ…å†µï¼‰
        merged_data['å‘è´§æ•°é‡'] = merged_data['å‘è´§æ•°é‡'].fillna(0)
        
        # è®¡ç®—å·®å¼‚
        merged_data['æ•°é‡å·®å¼‚'] = merged_data['è®¢å•æ•°é‡'] - merged_data['å‘è´§æ•°é‡']
        
        # åˆ¤æ–­æ˜¯å¦ä¸€è‡´
        merged_data['æ˜¯å¦ä¸€è‡´'] = merged_data['æ•°é‡å·®å¼‚'] == 0
        
        # åˆ†ç±»ç»“æœ
        consistent_records = merged_data[merged_data['æ˜¯å¦ä¸€è‡´']].copy()
        
        # ä¸ä¸€è‡´çš„è®°å½•åˆ†ä¸ºä¸¤ç§æƒ…å†µ
        inconsistent_records = merged_data[(~merged_data['æ˜¯å¦ä¸€è‡´']) & (merged_data['å‘è´§æ•°é‡'] > 0)].copy()  # æ•°é‡ä¸ä¸€è‡´
        not_found_records = merged_data[merged_data['å‘è´§æ•°é‡'] == 0].copy()  # å‘è´§æ˜ç»†ä¸­æ²¡æ‰¾åˆ°
        
        # æ·»åŠ è¯´æ˜åˆ—
        consistent_records['æ ¸å¯¹ç»“æœ'] = 'æ•°é‡ä¸€è‡´'
        inconsistent_records['æ ¸å¯¹ç»“æœ'] = 'æ•°é‡ä¸ä¸€è‡´'
        not_found_records['æ ¸å¯¹ç»“æœ'] = 'å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°'
        
        return consistent_records, inconsistent_records, not_found_records, pd.DataFrame()
        
    except Exception as e:
        st.error(f"æ•°æ®æ ¸å¯¹æ—¶å‡ºé”™: {e}")
        st.error(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        # è¿”å›ç©ºçš„DataFrame
        empty_df = pd.DataFrame()
        return empty_df, empty_df, empty_df, empty_df

def mark_procurement_info(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df):
    """
    æ ¹æ®ä¾›åº”å•†è®¢å•ä¸­çš„'ä¸€ä»¶ä»£å‘'å­—æ®µæ ‡è®°å‘è´§æ˜ç»†çš„'æ˜¯å¦é›†é‡‡'åˆ—
    """
    try:
        # ç­›é€‰ä¾›åº”å•†ä¸ºæ€¡äºšé€šçš„è®¢å•
        yiyatong_orders = ä¾›åº”å•†è®¢å•_df[ä¾›åº”å•†è®¢å•_df['ä¾›åº”å•†'].str.contains('æ€¡äºšé€š', na=False)].copy()
        
        # æ ¹æ®'ä¸€ä»¶ä»£å‘'åˆ—åˆ¤æ–­æ˜¯å¦é›†é‡‡ï¼ˆä¸€ä»¶ä»£å‘ä¸º'æ˜¯'è¡¨ç¤ºéé›†é‡‡ï¼‰
        yiyatong_orders['æ˜¯å¦é›†é‡‡'] = yiyatong_orders['ä¸€ä»¶ä»£å‘'].apply(
            lambda x: 'éé›†é‡‡' if str(x).strip() == 'æ˜¯' else 'é›†é‡‡'
        )
        
        # æŒ‰æ–¹æ¡ˆç¼–å·ã€æ”¶è´§äººã€è”ç³»æ–¹å¼å’Œå•†å“åç§°åˆ†ç»„ï¼Œç¡®å®šæ¯ä¸ªç»„åˆçš„é›†é‡‡çŠ¶æ€
        # å¦‚æœä»»ä½•ä¸€ä¸ªè®¢å•æ˜¯é›†é‡‡ï¼Œåˆ™æ•´ä¸ªç»„åˆä¸ºé›†é‡‡
        procurement_status = yiyatong_orders.groupby(['æ–¹æ¡ˆç¼–å·', 'æ”¶è´§äºº', 'è”ç³»æ–¹å¼', 'å•†å“åç§°'])['æ˜¯å¦é›†é‡‡'].apply(
            lambda x: 'é›†é‡‡' if 'é›†é‡‡' in x.values else 'éé›†é‡‡'
        ).reset_index()
        
        # åˆ›å»ºä¸€ä¸ªç”¨äºåŒ¹é…çš„å‘è´§æ˜ç»†å‰¯æœ¬
        å‘è´§æ˜ç»†_marked = å‘è´§æ˜ç»†_df.copy()
        
        # åˆå§‹åŒ–'æ˜¯å¦é›†é‡‡'åˆ—ä¸ºç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯None
        å‘è´§æ˜ç»†_marked['æ˜¯å¦é›†é‡‡'] = ''
        
        # æ ¹æ®åŒ¹é…æ¡ä»¶æ›´æ–°'æ˜¯å¦é›†é‡‡'åˆ—
        for _, row in procurement_status.iterrows():
            mask = (
                (å‘è´§æ˜ç»†_marked['é¢†ç”¨è¯´æ˜'] == row['æ–¹æ¡ˆç¼–å·']) &
                (å‘è´§æ˜ç»†_marked['æ”¶è´§äºº'] == row['æ”¶è´§äºº']) &
                (å‘è´§æ˜ç»†_marked['æ”¶è´§äººç”µè¯'] == row['è”ç³»æ–¹å¼']) &
                (å‘è´§æ˜ç»†_marked['äº§å“åç§°'] == row['å•†å“åç§°'])
            )
            å‘è´§æ˜ç»†_marked.loc[mask, 'æ˜¯å¦é›†é‡‡'] = row['æ˜¯å¦é›†é‡‡']
        
        return å‘è´§æ˜ç»†_marked
        
    except Exception as e:
        st.error(f"æ ‡è®°é›†é‡‡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        return å‘è´§æ˜ç»†_df

def extract_direct_mail_info(df, filename):
    """
    æ™ºèƒ½è¯†åˆ«ç›´é‚®è¡¨ä¸­çš„å…³é”®åˆ—å¹¶æå–æ•°æ®
    è¯†åˆ«è§„åˆ™ï¼š
    - æ‰‹æœºå·ï¼šåŒ…å«7-11ä½æ•°å­—çš„åˆ—
    - æ”¶è´§äººï¼šå¤§éƒ¨åˆ†æ˜¯2-4ä¸ªæ±‰å­—çš„åˆ—
    - åœ°å€ï¼šåŒ…å«è¾ƒé•¿æ–‡æœ¬çš„åˆ—
    - åº—åï¼šå•†æˆ·/åº—é“ºåç§°åˆ—
    """
    try:
        # 1. è¯†åˆ«å…³é”®åˆ—
        phone_col = None
        name_col = None
        address_col = None
        shop_col = None
        
        # åˆ†æå„åˆ—æ•°æ®ç‰¹å¾
        for col in df.columns:
            col_data = df[col].dropna().astype(str)
            if len(col_data) == 0:
                continue
                
            # è¯†åˆ«æ‰‹æœºå·åˆ—ï¼ˆåŒ…å«7-11ä½æ•°å­—ï¼‰
            if not phone_col:
                digit_counts = col_data.str.replace(r'\D', '', regex=True).str.len()
                if (digit_counts >= 7).mean() > 0.8:  # 80%ä»¥ä¸Šæ˜¯7ä½ä»¥ä¸Šæ•°å­—
                    phone_col = col
                    continue
                    
            # è¯†åˆ«æ”¶è´§äººåˆ—ï¼ˆå¤§éƒ¨åˆ†æ˜¯2-4ä¸ªæ±‰å­—ï¼‰
            if not name_col:
                name_lengths = col_data.str.len()
                chinese_chars = col_data.str.count(r'[\u4e00-\u9fa5]')
                if ((name_lengths >= 2) & (name_lengths <= 4)).mean() > 0.7 and (chinese_chars == name_lengths).mean() > 0.7:
                    name_col = col
                    continue
                    
            # è¯†åˆ«åœ°å€åˆ—ï¼ˆè¾ƒé•¿æ–‡æœ¬ï¼‰
            if not address_col:
                if (col_data.str.len() > 10).mean() > 0.7:
                    address_col = col
                    continue
                    
            # è¯†åˆ«åº—ååˆ—ï¼ˆéäººåã€éåœ°å€çš„æ–‡æœ¬ï¼‰
            if not shop_col:
                if (col_data.str.len() > 2).mean() > 0.7 and (col_data != df.get(phone_col, '')).all() and (col_data != df.get(name_col, '')).all():
                    shop_col = col
        
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
        st.write(f"è¯†åˆ«ç»“æœ: æ‰‹æœºâ†’{phone_col}, æ”¶è´§äººâ†’{name_col}, åœ°å€â†’{address_col}, åº—åâ†’{shop_col}")
        
        # 2. æå–æ•°æ®ï¼ˆè·³è¿‡ç¬¬ä¸€è¡Œï¼‰
        extracted_data = []
        for index, row in df.iloc[1:].iterrows():
            item = {
                'æ”¶è´§äºº': str(row.get(name_col, '')).strip() if name_col else '',
                'æ‰‹æœº': str(row.get(phone_col, '')).strip() if phone_col else '',
                'æ”¶è´§åœ°å€': str(row.get(address_col, '')).strip() if address_col else '',
                'å®¢æˆ·å¤‡æ³¨': str(row.get(shop_col, '')).strip() if shop_col else '',
                'æºæ–‡ä»¶': filename
            }
            
            # éªŒè¯æ•°æ®æœ‰æ•ˆæ€§
            if not item['æ”¶è´§äºº'] and not item['æ‰‹æœº']:
                continue
                
            # ç¡®ä¿æ‰‹æœºå·åªåŒ…å«æ•°å­—
            if item['æ‰‹æœº']:
                item['æ‰‹æœº'] = ''.join(c for c in item['æ‰‹æœº'] if c.isdigit())[:11]
                
            extracted_data.append(item)
        
        # æ˜¾ç¤ºæå–ç»“æœç¤ºä¾‹
        if extracted_data:
            st.write("æå–æ•°æ®ç¤ºä¾‹:")
            st.dataframe(pd.DataFrame(extracted_data[:3]))
        
        return extracted_data
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {filename} æ—¶å‡ºé”™: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return []

if app_mode == "æ‰¹é‡å¤„ç†å‘æ”¾æ˜ç»†":
    st.header("æ‰¹é‡å¤„ç†å‘æ”¾æ˜ç»†")

    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ å‘æ”¾æ˜ç»†æŸ¥è¯¢æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
        type=["xlsx"],
        accept_multiple_files=True
    )

    if uploaded_files:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶å
        file_names = [f.name for f in uploaded_files]
        st.write("ä¸Šä¼ çš„æ–‡ä»¶:")
        st.write(file_names)
        
        # å¤„ç†æŒ‰é’®
        if st.button("å¼€å§‹å¤„ç†"):
            with st.spinner("æ­£åœ¨å¤„ç†æ–‡ä»¶..."):
                result_df = batch_process_files(uploaded_files)
                
                if result_df is not None and not result_df.empty:
                    st.success(f"å¤„ç†å®Œæˆï¼å…±æ±‡æ€» {len(result_df)} è¡Œæ•°æ®")
                    
                    # æ˜¾ç¤ºç»“æœé¢„è§ˆ
                    st.subheader("å¤„ç†ç»“æœé¢„è§ˆ")
                    st.dataframe(result_df.head(20))
                    
                    # æä¾›ä¸‹è½½
                    output_file = f"å‘è´§æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    save_with_formatting(result_df, output_file)
                    
                    with open(output_file, "rb") as file:
                        st.download_button(
                            label="ä¸‹è½½å¤„ç†ç»“æœ",
                            data=file,
                            file_name=output_file,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                else:
                    st.error("å¤„ç†å¤±è´¥æˆ–æ²¡æœ‰æ•°æ®")

elif app_mode == "æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•":
    st.header("æ ¸å¯¹å‘è´§æ˜ç»†ä¸ä¾›åº”å•†è®¢å•")
    st.info("æ­¤åŠŸèƒ½ç”¨äºæ ¸å¯¹ä¾›åº”å•†è®¢å•ä¸­æ€¡äºšé€šçš„æ•°æ®ä¸å‘è´§æ˜ç»†æ˜¯å¦ä¸€è‡´")
    
    col1, col2 = st.columns(2)
    
    with col1:
        delivery_file = st.file_uploader(
            "ä¸Šä¼ å‘è´§æ˜ç»†æ–‡ä»¶",
            type=["xlsx"],
            key="delivery_file"
        )
    
    with col2:
        order_files = st.file_uploader(
            "ä¸Šä¼ ä¾›åº”å•†è®¢å•æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰",
            type=["xlsx"],
            accept_multiple_files=True,
            key="order_files"
        )
    
    if delivery_file and order_files:
        if st.button("å¼€å§‹æ ¸å¯¹"):
            with st.spinner("æ­£åœ¨æ ¸å¯¹æ•°æ®..."):
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                with tempfile.TemporaryDirectory() as temp_dir:
                    # ä¿å­˜å‘è´§æ˜ç»†æ–‡ä»¶
                    delivery_path = os.path.join(temp_dir, delivery_file.name)
                    with open(delivery_path, "wb") as f:
                        f.write(delivery_file.getbuffer())
                    
                    # è¯»å–å‘è´§æ˜ç»†
                    try:
                        å‘è´§æ˜ç»†_df = pd.read_excel(delivery_path)
                        st.info(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶ï¼Œå…± {len(å‘è´§æ˜ç»†_df)} è¡Œæ•°æ®")
                    except Exception as e:
                        st.error(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                        st.stop()
                    
                    # ä¿å­˜ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    order_file_paths = []
                    for uploaded_file in order_files:
                        file_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        order_file_paths.append(file_path)
                    
                    # å¤„ç†æ‰€æœ‰ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    all_orders = []
                    for file_path in order_file_paths:
                        with st.spinner(f"æ­£åœ¨å¤„ç† {os.path.basename(file_path)}..."):
                            df = process_supplier_order_file(file_path)
                            if df is not None:
                                all_orders.append(df)
                                st.success(f"æˆåŠŸå¤„ç† {os.path.basename(file_path)}")
                    
                    if all_orders:
                        # åˆå¹¶æ‰€æœ‰è®¢å•æ•°æ®
                        ä¾›åº”å•†è®¢å•_df = pd.concat(all_orders, ignore_index=True)
                        st.info(f"åˆå¹¶è®¢å•æ•°æ®ï¼Œå…± {len(ä¾›åº”å•†è®¢å•_df)} è¡Œ")
                        
                        # è¿›è¡Œæ•°æ®æ ¸å¯¹
                        consistent_records, inconsistent_records, not_found_records, _ = compare_data(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df)
                        
                        # æ˜¾ç¤ºæ ¸å¯¹ç»“æœ
                        st.success("æ•°æ®æ ¸å¯¹å®Œæˆï¼")
                        
                        # æ˜¾ç¤ºä¸€è‡´çš„è®°å½•
                        if not consistent_records.empty:
                            st.subheader("æ•°é‡ä¸€è‡´çš„è®°å½•")
                            st.dataframe(consistent_records)
                            st.success(f"å‘ç° {len(consistent_records)} æ¡æ•°é‡ä¸€è‡´çš„è®°å½•")
                        
                        # æ˜¾ç¤ºæ•°é‡ä¸ä¸€è‡´çš„è®°å½•
                        if not inconsistent_records.empty:
                            st.subheader("æ•°é‡ä¸ä¸€è‡´çš„è®°å½•")
                            st.dataframe(inconsistent_records)
                            st.warning(f"å‘ç° {len(inconsistent_records)} æ¡æ•°é‡ä¸ä¸€è‡´çš„è®°å½•")
                        
                        # æ˜¾ç¤ºå‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°çš„è®°å½•
                        if not not_found_records.empty:
                            st.subheader("å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°çš„è®°å½•")
                            st.dataframe(not_found_records)
                            st.error(f"å‘ç° {len(not_found_records)} æ¡å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°çš„è®°å½•")
                        
                        # ç»Ÿè®¡ä¿¡æ¯
                        total_records = len(consistent_records) + len(inconsistent_records) + len(not_found_records)
                        consistent_count = len(consistent_records)
                        st.info(f"æ€»å…±æ ¸å¯¹ {total_records} æ¡ä¾›åº”å•†è®¢å•è®°å½•")
                        st.info(f"  - æ•°é‡ä¸€è‡´: {consistent_count} æ¡")
                        st.info(f"  - æ•°é‡ä¸ä¸€è‡´: {len(inconsistent_records)} æ¡")
                        st.info(f"  - å‘è´§æ˜ç»†ä¸­æœªæ‰¾åˆ°: {len(not_found_records)} æ¡")
                        
                        # æä¾›ä¸‹è½½
                        output_file = f"æ ¸å¯¹ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                        # åˆå¹¶ç»“æœ
                        combined_result = pd.concat([consistent_records, inconsistent_records, not_found_records], ignore_index=True)
                        save_with_formatting(combined_result, output_file)
                        
                        with open(output_file, "rb") as file:
                            st.download_button(
                                label="ä¸‹è½½æ ¸å¯¹ç»“æœ",
                                data=file,
                                file_name=output_file,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                    else:
                        st.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ä¾›åº”å•†è®¢å•æ–‡ä»¶")

elif app_mode == "æ ‡è®°å‘è´§æ˜ç»†é›†é‡‡ä¿¡æ¯":
    st.header("æ ‡è®°å‘è´§æ˜ç»†é›†é‡‡ä¿¡æ¯")
    st.info("æ­¤åŠŸèƒ½æ ¹æ®ä¾›åº”å•†è®¢å•ä¸­çš„'ä¸€ä»¶ä»£å‘'å­—æ®µæ ‡è®°å‘è´§æ˜ç»†çš„'æ˜¯å¦é›†é‡‡'åˆ—")
    
    col1, col2 = st.columns(2)
    
    with col1:
        delivery_file = st.file_uploader(
            "ä¸Šä¼ å‘è´§æ˜ç»†æ–‡ä»¶",
            type=["xlsx"],
            key="delivery_file_procurement"
        )
    
    with col2:
        order_files = st.file_uploader(
            "ä¸Šä¼ ä¾›åº”å•†è®¢å•æ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªï¼‰",
            type=["xlsx"],
            accept_multiple_files=True,
            key="order_files_procurement"
        )
    
    if delivery_file and order_files:
        if st.button("å¼€å§‹æ ‡è®°"):
            with st.spinner("æ­£åœ¨æ ‡è®°é›†é‡‡ä¿¡æ¯..."):
                # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                with tempfile.TemporaryDirectory() as temp_dir:
                    # ä¿å­˜å‘è´§æ˜ç»†æ–‡ä»¶
                    delivery_path = os.path.join(temp_dir, delivery_file.name)
                    with open(delivery_path, "wb") as f:
                        f.write(delivery_file.getbuffer())
                    
                    # è¯»å–å‘è´§æ˜ç»†
                    try:
                        å‘è´§æ˜ç»†_df = pd.read_excel(delivery_path)
                        st.info(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶ï¼Œå…± {len(å‘è´§æ˜ç»†_df)} è¡Œæ•°æ®")
                    except Exception as e:
                        st.error(f"è¯»å–å‘è´§æ˜ç»†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                        st.stop()
                    
                    # ä¿å­˜ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    order_file_paths = []
                    for uploaded_file in order_files:
                        file_path = os.path.join(temp_dir, uploaded_file.name)
                        with open(file_path, "wb") as f:
                            f.write(uploaded_file.getbuffer())
                        order_file_paths.append(file_path)
                    
                    # å¤„ç†æ‰€æœ‰ä¾›åº”å•†è®¢å•æ–‡ä»¶
                    all_orders = []
                    for file_path in order_file_paths:
                        with st.spinner(f"æ­£åœ¨å¤„ç† {os.path.basename(file_path)}..."):
                            df = process_supplier_order_file(file_path)
                            if df is not None:
                                all_orders.append(df)
                                st.success(f"æˆåŠŸå¤„ç† {os.path.basename(file_path)}")
                    
                    if all_orders:
                        # åˆå¹¶æ‰€æœ‰è®¢å•æ•°æ®
                        ä¾›åº”å•†è®¢å•_df = pd.concat(all_orders, ignore_index=True)
                        st.info(f"åˆå¹¶è®¢å•æ•°æ®ï¼Œå…± {len(ä¾›åº”å•†è®¢å•_df)} è¡Œ")
                        
                        # æ ‡è®°é›†é‡‡ä¿¡æ¯
                        marked_df = mark_procurement_info(å‘è´§æ˜ç»†_df, ä¾›åº”å•†è®¢å•_df)
                        
                        if marked_df is not None:
                            st.success("é›†é‡‡ä¿¡æ¯æ ‡è®°å®Œæˆï¼")
                            
                            # æ˜¾ç¤ºæ ‡è®°ç»“æœç»Ÿè®¡ï¼ˆåŒ…å«ç©ºç™½çš„è¯´æ˜ï¼‰
                            procurement_stats = marked_df['æ˜¯å¦é›†é‡‡'].value_counts()
                            st.subheader("é›†é‡‡æ ‡è®°ç»Ÿè®¡")
                            st.write("æ³¨æ„ï¼šç©ºç™½è¡¨ç¤ºå‘è´§æ˜ç»†ä¸­æœ‰ä½†ä¾›åº”å•†è®¢å•ä¸­æ²¡æœ‰çš„è®°å½•")
                            st.write(procurement_stats)
                            # å•ç‹¬ç»Ÿè®¡ç©ºç™½æ•°é‡
                            blank_count = len(marked_df[marked_df['æ˜¯å¦é›†é‡‡'] == ''])
                            if blank_count > 0:
                                st.info(f"å…±æœ‰ {blank_count} è¡Œè®°å½•åœ¨ä¾›åº”å•†è®¢å•ä¸­æœªæ‰¾åˆ°å¯¹åº”ä¿¡æ¯ï¼ˆæ˜¾ç¤ºä¸ºç©ºç™½ï¼‰")
                            
                            # æ˜¾ç¤ºéƒ¨åˆ†æ ‡è®°ç»“æœ
                            st.subheader("æ ‡è®°ç»“æœé¢„è§ˆ")
                            preview_df = marked_df[['é¢†ç”¨è¯´æ˜', 'æ”¶è´§äºº', 'æ”¶è´§äººç”µè¯', 'äº§å“åç§°', 'æ•°é‡', 'æ˜¯å¦é›†é‡‡']].head(20)
                            st.dataframe(preview_df)
                            
                            # æä¾›ä¸‹è½½
                            output_file = f"å‘è´§æ˜ç»†_å«é›†é‡‡ä¿¡æ¯_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            save_with_formatting(marked_df, output_file)
                            
                            with open(output_file, "rb") as file:
                                st.download_button(
                                    label="ä¸‹è½½æ ‡è®°ç»“æœ",
                                    data=file,
                                    file_name=output_file,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        else:
                            st.error("æ ‡è®°é›†é‡‡ä¿¡æ¯æ—¶å‡ºç°é”™è¯¯")
                    else:
                        st.error("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•ä¾›åº”å•†è®¢å•æ–‡ä»¶")

elif app_mode == "å¯¼å…¥ç›´é‚®æ˜ç»†åˆ°ä¸‰æ‹©å¯¼å•":
    st.header("å¯¼å…¥ç›´é‚®æ˜ç»†åˆ°ä¸‰æ‹©å¯¼å•")
    st.info("è¯·æŒ‰æ­¥éª¤æ“ä½œï¼š1.ä¸Šä¼ ä¸‰æ‹©å¯¼å• 2.ä¸Šä¼ ç›´é‚®æ–‡ä»¶å¹¶é€‰æ‹©åˆ—æ˜ å°„")
    
    # å•†å“åˆ—è¡¨
    product_list = [
        "å¥¥å…‹æ–¯ï¼ˆAUXï¼‰ é™¤è¨ä»ª 90W ï¼ˆè®¡ä»·å•ä½ï¼šå°ï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰  ç›’è£…æŠ½çº¸  ï¼ˆè®¡ä»·å•ä½ï¼šç›’ï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ ç¯ä¿å¡‘æ–™è¢‹  50ä¸ª/æ† 300ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ ä¸¤ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ æ¹¿çº¸å·¾ 10ç‰‡/åŒ… ï¼ˆè®¡ä»·å•ä½ï¼šåŒ…ï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ å››ç›’è£…ç¿»ç›–å¼ç¤¼ç›’ 30ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ å››ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¤©å¶å“ç³»ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ å¤©å¶åæ¯«å…‹   ä¸¤æ¡è£…çº¸è¢‹ ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆå¸¸è§„æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆç»†æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "é»„é‡‘è‘‰ äº”ç›’è£…ç®€æ˜“å°å¥—ï¼ˆä¸­æ”¯æ¬¾ï¼‰ 50ä¸ª/ç®± ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ å›½äº§å®šåˆ¶",
        "å“èƒœï¼ˆPISENï¼‰ æ•°æ®çº¿ä¸‰åˆä¸€å……ç”µçº¿100W  ä¸€æ‹–ä¸‰ ï¼ˆè®¡ä»·å•ä½ï¼šæ¡ï¼‰ æœ‰è‰²",
        "å‰ƒé¡»åˆ€ä¾¿æºåˆé‡‘ç”µåŠ¨åˆ®èƒ¡åˆ€ç”·å£«  MINI 2.0 ï¼ˆè®¡ä»·å•ä½ï¼šä¸ªï¼‰ é¢œè‰²éšæœº"
    ]
    
    # åˆå§‹åŒ–session state
    if 'processed_data_list' not in st.session_state:
        st.session_state.processed_data_list = []
    if 'show_import_success' not in st.session_state:
        st.session_state.show_import_success = False
    if 'selected_product' not in st.session_state:
        st.session_state.selected_product = ""
    if 'product_quantity' not in st.session_state:
        st.session_state.product_quantity = 1
    if 'download_triggered' not in st.session_state:
        st.session_state.download_triggered = False
    
    # æ­¥éª¤1ï¼šä¸Šä¼ ä¸‰æ‹©å¯¼å•
    sanze_file = st.file_uploader("1. ä¸Šä¼ ä¸‰æ‹©å¯¼å•æ–‡ä»¶", type=["xlsx"], key="sanze_file")
    
    if sanze_file:
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä»¥ç¡®ä¿å¯å†™æƒé™
            with tempfile.NamedTemporaryFile(suffix='.xlsx', delete=False) as tmp_file:
                tmp_file.write(sanze_file.getvalue())
                tmp_file_path = tmp_file.name
            
            # ä»ä¸´æ—¶æ–‡ä»¶è¯»å–ä¸‰æ‹©å¯¼å•
            sanze_df = pd.read_excel(tmp_file_path)
            st.success(f"ä¸‰æ‹©å¯¼å•å·²åŠ è½½ï¼ˆå…±{len(sanze_df)}è¡Œï¼‰")
            
            # ç¡®ä¿æœ‰å®¢æˆ·å¤‡æ³¨åˆ—å’Œè´§å“åç§°ã€æ•°é‡åˆ—
            if 'å®¢æˆ·å¤‡æ³¨' not in sanze_df.columns:
                sanze_df['å®¢æˆ·å¤‡æ³¨'] = ''
            if 'è´§å“åç§°' not in sanze_df.columns:
                sanze_df['è´§å“åç§°'] = ''
            if 'æ•°é‡' not in sanze_df.columns:
                sanze_df['æ•°é‡'] = ''
            
            # æ­¥éª¤2ï¼šå¤„ç†ç›´é‚®æ–‡ä»¶
            st.subheader("2. å¤„ç†ç›´é‚®æ˜ç»†æ–‡ä»¶")
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ ç›´é‚®æ˜ç»†æ–‡ä»¶", 
                type=["xlsx"],
                key="direct_mail_current"
            )
            
            if uploaded_file:
                # æ·»åŠ åˆ—åè¡Œé€‰æ‹©åŠŸèƒ½
                st.subheader("3. é€‰æ‹©åˆ—åæ‰€åœ¨è¡Œ")
                header_option = st.radio(
                    "è¯·é€‰æ‹©åˆ—åæ‰€åœ¨çš„è¡Œï¼ˆæŸ¥çœ‹ä¸‹é¢çš„é¢„è§ˆæ¥ç¡®å®šï¼‰",
                    options=[0, 1],
                    format_func=lambda x: f"ç¬¬{x+1}è¡Œ",
                    key="header_option"
                )
                
                # è¯»å–å‰3è¡Œæ•°æ®ç”¨äºé¢„è§ˆ
                preview_df = pd.read_excel(uploaded_file, header=None, nrows=3)
                st.write("å‰ä¸‰è¡Œæ•°æ®é¢„è§ˆï¼ˆç”¨äºç¡®å®šåˆ—åæ‰€åœ¨è¡Œï¼‰:")
                st.dataframe(preview_df)
                
                # æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„åˆ—åè¡Œé‡æ–°è¯»å–æ•°æ®
                df = pd.read_excel(uploaded_file, header=header_option)
                
                st.write(f"ä½¿ç”¨ç¬¬{header_option+1}è¡Œä½œä¸ºåˆ—ååçš„æ•°æ®é¢„è§ˆ:")
                st.dataframe(df.head(5))
                
                # å•†å“é€‰æ‹©ç•Œé¢ï¼ˆåªèƒ½é€‰æ‹©ä¸€ä¸ªå•†å“ï¼‰
                st.subheader("4. é€‰æ‹©å•†å“å’Œæ•°é‡")
                selected_product = st.selectbox("é€‰æ‹©å•†å“", [""] + product_list, 
                                              index=product_list.index(st.session_state.selected_product) + 1 
                                              if st.session_state.selected_product in product_list else 0,
                                              key="product_selector")
                st.session_state.selected_product = selected_product
                
                product_quantity = st.number_input("æ•°é‡", min_value=1, value=st.session_state.product_quantity, key="quantity_selector")
                st.session_state.product_quantity = product_quantity
                
                # åˆ—é€‰æ‹©ç•Œé¢
                st.subheader("5. è¯·é€‰æ‹©å¯¹åº”åˆ—")
                cols = st.columns(2)
                with cols[0]:
                    name_col = st.selectbox("æ”¶è´§äººåˆ—", df.columns, key="name_col")
                    phone_col = st.selectbox("ç”µè¯åˆ—", df.columns, key="phone_col")
                with cols[1]:
                    address_col = st.selectbox("åœ°å€åˆ—", df.columns, key="address_col")
                    shop_col = st.selectbox("åº—ååˆ—", df.columns, key="shop_col")
                
                # å¤„ç†æŒ‰é’®
                if st.button("å¤„ç†å½“å‰æ–‡ä»¶"):
                    processed = []
                    for _, row in df.iterrows():
                        item = {
                            'æ”¶è´§äºº': str(row[name_col]).strip() if pd.notna(row[name_col]) else '',
                            'æ‰‹æœº': str(row[phone_col]).strip() if pd.notna(row[phone_col]) else '',
                            'æ”¶è´§åœ°å€': str(row[address_col]).strip() if pd.notna(row[address_col]) else '',
                            'å®¢æˆ·å¤‡æ³¨': str(row[shop_col]).strip() if pd.notna(row[shop_col]) else '',
                            'å•†å“åç§°': st.session_state.selected_product,
                            'å•†å“æ•°é‡': st.session_state.product_quantity
                        }
                        if item['æ”¶è´§äºº'] or item['æ‰‹æœº']:
                            processed.append(item)
                    
                    # å°†å½“å‰å¤„ç†çš„æ–‡ä»¶æ•°æ®æ·»åŠ åˆ°åˆ—è¡¨ä¸­
                    st.session_state.processed_data_list.append({
                        'filename': uploaded_file.name,
                        'data': processed
                    })
                    st.session_state.show_import_success = False
                    st.session_state.download_triggered = False
                    st.success(f"æˆåŠŸå¤„ç†{len(processed)}è¡Œæ•°æ®")
                    
                    # åˆ›å»ºä¸€ä¸ªå®‰å…¨çš„DataFrameç”¨äºæ˜¾ç¤º
                    display_data = []
                    for item in processed[:10]:  # åªæ˜¾ç¤ºå‰10è¡Œ
                        display_item = {
                            'æ”¶è´§äºº': item['æ”¶è´§äºº'],
                            'æ‰‹æœº': item['æ‰‹æœº'],
                            'æ”¶è´§åœ°å€': item['æ”¶è´§åœ°å€'],
                            'å®¢æˆ·å¤‡æ³¨': item['å®¢æˆ·å¤‡æ³¨'],
                            'å•†å“åç§°': item['å•†å“åç§°'],
                            'å•†å“æ•°é‡': item['å•†å“æ•°é‡']
                        }
                        display_data.append(display_item)
                    
                    display_df = pd.DataFrame(display_data)
                    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
                    for col in display_df.columns:
                        display_df[col] = display_df[col].astype(str)
                    st.dataframe(display_df)
                
                # æ˜¾ç¤ºå·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨å’Œå¯¼å…¥æŒ‰é’®
                if st.session_state.processed_data_list:
                    st.subheader("å·²å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨")
                    for i, item in enumerate(st.session_state.processed_data_list):
                        st.write(f"{i+1}. {item['filename']} ({len(item['data'])} è¡Œæ•°æ®)")
                    
                    # æ·»åŠ åˆ°ä¸‰æ‹©å¯¼å•æŒ‰é’®æ”¾åœ¨å·²å¤„ç†æ–‡ä»¶åˆ—è¡¨ä¸‹æ–¹
                    if st.button("ç¡®è®¤å¯¼å…¥åˆ°ä¸‰æ‹©å¯¼å•"):
                        total_imported = 0
                        for processed_item in st.session_state.processed_data_list:
                            processed_data = processed_item['data']
                            for item in processed_data:
                                new_row = {col: '' for col in sanze_df.columns}
                                new_row.update({
                                    'æ”¶è´§äºº': item['æ”¶è´§äºº'],
                                    'æ‰‹æœº': item['æ‰‹æœº'],
                                    'æ”¶è´§åœ°å€': item['æ”¶è´§åœ°å€'],
                                    'å®¢æˆ·å¤‡æ³¨': item['å®¢æˆ·å¤‡æ³¨'],
                                    'è´§å“åç§°': item['å•†å“åç§°'],
                                    'æ•°é‡': item['å•†å“æ•°é‡']
                                })
                                sanze_df.loc[len(sanze_df)] = new_row
                                total_imported += 1
                        
                        st.session_state.show_import_success = True
                        st.session_state.download_triggered = False
                
                if st.session_state.show_import_success:
                    st.success(f"å¯¼å…¥å®Œæˆï¼Œä¸‰æ‹©å¯¼å•ç°æœ‰{len(sanze_df)}è¡Œ")
                    
                    # ä¸‹è½½æ›´æ–°åçš„æ–‡ä»¶ï¼Œæ–‡ä»¶åç²¾ç¡®åˆ°ç§’
                    output = f"ä¸‰æ‹©å¯¼å•_æ›´æ–°_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    sanze_df.to_excel(output, index=False)
                    
                    with open(output, "rb") as f:
                        st.download_button("ä¸‹è½½æ›´æ–°åçš„ä¸‰æ‹©å¯¼å•", f, file_name=output)
                    
                    # å¯¼å…¥å®Œæˆåæ¸…ç©ºå·²å¤„ç†æ•°æ®åˆ—è¡¨
                    if st.button("æ¸…ç©ºå·²å¤„ç†æ–‡ä»¶åˆ—è¡¨å¹¶å¼€å§‹ä¸‹ä¸€è½®å¯¼å…¥"):
                        st.session_state.processed_data_list = []
                        st.session_state.show_import_success = False
                        st.session_state.selected_product = ""
                        st.session_state.product_quantity = 1
                        st.session_state.download_triggered = False
                        st.rerun()
                        
        except Exception as e:
            st.error(f"å¤„ç†ä¸‰æ‹©å¯¼å•æ—¶å‡ºé”™: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

# æ·»åŠ æ–°çš„åŠŸèƒ½æ¨¡å—
elif app_mode == "å¢å¼ºç‰ˆVLOOKUP":
    st.header("å¢å¼ºç‰ˆVLOOKUP")
    st.info("æ­¤åŠŸèƒ½å…è®¸æ‚¨ä»å‚è€ƒè¡¨ä¸­æ‰¹é‡åŒ¹é…å¤šä¸ªåˆ—åˆ°ä¸»è¡¨ä¸­")
    
    # åˆå§‹åŒ–session state
    if 'vlookup_processed' not in st.session_state:
        st.session_state.vlookup_processed = False
    if 'vlookup_result' not in st.session_state:
        st.session_state.vlookup_result = None
    
    col1, col2 = st.columns(2)
    
    with col1:
        main_file = st.file_uploader("ä¸Šä¼ ä¸»è¡¨æ–‡ä»¶", type=["xlsx"], key="main_file")
    
    with col2:
        reference_file = st.file_uploader("ä¸Šä¼ å‚è€ƒè¡¨æ–‡ä»¶", type=["xlsx"], key="reference_file")
    
    if main_file and reference_file:
        try:
            # è¯»å–ä¸¤ä¸ªæ–‡ä»¶
            main_df = pd.read_excel(main_file)
            reference_df = pd.read_excel(reference_file)
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
            for col in main_df.columns:
                main_df[col] = main_df[col].astype(str)
                
            for col in reference_df.columns:
                reference_df[col] = reference_df[col].astype(str)
            
            st.subheader("ä¸»è¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(main_df.head(10))
            
            st.subheader("å‚è€ƒè¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(reference_df.head(10))
            
            # é€‰æ‹©åŒ¹é…åˆ—
            st.subheader("é…ç½®åŒ¹é…å‚æ•°")
            
            # è·å–æ‰€æœ‰åˆ—å
            main_columns = main_df.columns.tolist()
            reference_columns = reference_df.columns.tolist()
            
            # é€‰æ‹©ç”¨äºåŒ¹é…çš„åˆ—ï¼ˆæ”¯æŒå¤šé€‰ï¼‰
            st.write("é€‰æ‹©ç”¨äºåŒ¹é…çš„åˆ—ï¼ˆæ”¯æŒå¤šåˆ—ç»„åˆåŒ¹é…ï¼‰:")
            match_cols_main = st.multiselect("ä¸»è¡¨ä¸­çš„åŒ¹é…åˆ—", main_columns, key="match_cols_main", max_selections=len(main_columns))
            match_cols_ref = st.multiselect("å‚è€ƒè¡¨ä¸­çš„åŒ¹é…åˆ—ï¼ˆè¯·æŒ‰ä¸ä¸»è¡¨ç›¸åŒçš„é¡ºåºé€‰æ‹©ï¼‰", reference_columns, key="match_cols_ref", max_selections=len(reference_columns))
            
            # éªŒè¯åŒ¹é…åˆ—é€‰æ‹©
            if len(match_cols_main) != len(match_cols_ref):
                st.warning("ä¸»è¡¨å’Œå‚è€ƒè¡¨çš„åŒ¹é…åˆ—æ•°é‡å¿…é¡»ç›¸åŒ")
            elif len(match_cols_main) == 0:
                st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—ç”¨äºåŒ¹é…")
            else:
                # æ˜¾ç¤ºåŒ¹é…åˆ—å¯¹åº”å…³ç³»
                st.write("åŒ¹é…åˆ—å¯¹åº”å…³ç³»:")
                match_df = pd.DataFrame({
                    'ä¸»è¡¨åˆ—å': match_cols_main,
                    'å‚è€ƒè¡¨åˆ—å': match_cols_ref
                })
                st.table(match_df)
                
                # é€‰æ‹©è¦ä»å‚è€ƒè¡¨æ·»åŠ çš„åˆ—
                st.write("é€‰æ‹©è¦ä»å‚è€ƒè¡¨æ·»åŠ åˆ°ä¸»è¡¨çš„åˆ—:")
                # æ’é™¤å·²ç”¨äºåŒ¹é…çš„åˆ—
                available_columns = [col for col in reference_columns if col not in match_cols_ref]
                columns_to_add = st.multiselect("é€‰æ‹©åˆ—", available_columns, key="columns_to_add")
                
                # é€‰æ‹©åŒ¹é…æ–¹å¼
                st.write("åŒ¹é…æ–¹å¼:")
                join_type = st.radio("é€‰æ‹©è¿æ¥æ–¹å¼", 
                                    ["LEFT JOIN (ä¿ç•™ä¸»è¡¨æ‰€æœ‰è¡Œ)", 
                                     "INNER JOIN (åªä¿ç•™ä¸¤è¡¨åŒ¹é…çš„è¡Œ)"], 
                                    key="join_type")
                
                # å¤„ç†é‡å¤é¡¹é€‰é¡¹
                st.subheader("é‡å¤é¡¹å¤„ç†")
                handle_duplicates = st.radio(
                    "å¦‚ä½•å¤„ç†å‚è€ƒè¡¨ä¸­çš„é‡å¤åŒ¹é…è®°å½•",
                    ["ä¿ç•™ç¬¬ä¸€æ¡è®°å½•", "åˆå¹¶æ‰€æœ‰è®°å½•ï¼ˆå¯èƒ½å¯¼è‡´è¡Œæ•°å¢åŠ ï¼‰"],
                    index=0,
                    key="vlookup_handle_duplicates"
                )
                
                if st.button("æ‰§è¡Œå¢å¼ºVLOOKUP"):
                    if columns_to_add:
                        with st.spinner("æ­£åœ¨æ‰§è¡Œå¢å¼ºVLOOKUP..."):
                            try:
                                # å¤„ç†å‚è€ƒè¡¨ä¸­çš„é‡å¤è®°å½•
                                if handle_duplicates == "ä¿ç•™ç¬¬ä¸€æ¡è®°å½•":
                                    # å¯¹äºæ¯ä¸ªåŒ¹é…é”®ï¼Œåªä¿ç•™ç¬¬ä¸€æ¡è®°å½•
                                    reference_df_unique = reference_df.drop_duplicates(subset=match_cols_ref, keep='first')
                                    st.info(f"å‚è€ƒè¡¨ä¸­é‡å¤çš„åŒ¹é…è®°å½•å·²è¢«ç§»é™¤ï¼Œå‰©ä½™ {len(reference_df_unique)} æ¡è®°å½•")
                                else:
                                    reference_df_unique = reference_df
                                    st.info(f"ä¿ç•™å‚è€ƒè¡¨ä¸­çš„æ‰€æœ‰è®°å½•ï¼Œå…± {len(reference_df_unique)} æ¡è®°å½•")
                                
                                # ä¿å­˜ä¸»è¡¨çš„åŸå§‹ç´¢å¼•
                                main_df_with_index = main_df.reset_index()
                                
                                # æ‰§è¡Œå¢å¼ºç‰ˆVLOOKUP
                                if join_type == "LEFT JOIN (ä¿ç•™ä¸»è¡¨æ‰€æœ‰è¡Œ)":
                                    # ä½¿ç”¨left joinç¡®ä¿ä¿ç•™ä¸»è¡¨çš„æ‰€æœ‰è¡Œå’Œé¡ºåº
                                    merged_temp = pd.merge(main_df_with_index, 
                                                         reference_df_unique[match_cols_ref + columns_to_add], 
                                                         left_on=match_cols_main, 
                                                         right_on=match_cols_ref, 
                                                         how='left',
                                                         sort=False)  # ä¿æŒåŸæœ‰é¡ºåº
                                else:
                                    # INNER JOIN
                                    merged_temp = pd.merge(main_df_with_index, 
                                                         reference_df_unique[match_cols_ref + columns_to_add], 
                                                         left_on=match_cols_main, 
                                                         right_on=match_cols_ref, 
                                                         how='inner',
                                                         sort=False)  # ä¿æŒåŸæœ‰é¡ºåº
                                
                                # æ¢å¤åŸå§‹ç´¢å¼•å¹¶æ’åºï¼Œç¡®ä¿è¡Œé¡ºåºä¸ä¸»è¡¨ä¸€è‡´
                                result_df = merged_temp.sort_values('index').drop('index', axis=1).reset_index(drop=True)
                                
                                # ç¡®ä¿ç»“æœDataFrameçš„æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                                for col in result_df.columns:
                                    result_df[col] = result_df[col].astype(str)
                                
                                st.success("å¢å¼ºVLOOKUPæ‰§è¡Œå®Œæˆï¼")
                                st.subheader("ç»“æœç»Ÿè®¡")
                                st.write(f"åŸå§‹ä¸»è¡¨è¡Œæ•°: {len(main_df)}")
                                st.write(f"åŒ¹é…åç»“æœè¡Œæ•°: {len(result_df)}")
                                
                                if len(result_df) > len(main_df):
                                    st.warning("æ³¨æ„ï¼šç»“æœè¡Œæ•°å¢åŠ ï¼Œè¿™æ˜¯å› ä¸ºæŸäº›è®°å½•åœ¨å‚è€ƒè¡¨ä¸­æœ‰å¤šæ¡åŒ¹é…è®°å½•")
                                
                                st.subheader("ç»“æœé¢„è§ˆ")
                                st.dataframe(result_df.head(20))
                                
                                # æä¾›ä¸‹è½½
                                output_file = f"å¢å¼ºVLOOKUPç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                                result_df.to_excel(output_file, index=False)
                                
                                with open(output_file, "rb") as file:
                                    st.download_button(
                                        label="ä¸‹è½½ç»“æœæ–‡ä»¶",
                                        data=file,
                                        file_name=output_file,
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                    )
                            except Exception as e:
                                st.error(f"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                                import traceback
                                st.error(traceback.format_exc())
                    else:
                        st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—æ·»åŠ åˆ°ä¸»è¡¨ä¸­")
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

elif app_mode == "ç‰©æµå•å·åŒ¹é…":
    st.header("ç‰©æµå•å·åŒ¹é…")
    st.info("æ­¤åŠŸèƒ½ç”¨äºå°†ç‰©æµå•å·è¡¨ä¸­çš„å¿«é€’å…¬å¸ã€å•å·å’Œé¢å¤–å•å·ä¿¡æ¯åŒ¹é…åˆ°å¾…å‘è´§æ˜ç»†è¡¨ä¸­")
    
    col1, col2 = st.columns(2)
    
    with col1:
        pending_shipment_file = st.file_uploader("ä¸Šä¼ å¾…å‘è´§æ˜ç»†è¡¨", type=["xlsx"], key="pending_shipment_file")
    
    with col2:
        logistics_file = st.file_uploader("ä¸Šä¼ ç‰©æµå•å·è¡¨", type=["xlsx"], key="logistics_file")
    
    if pending_shipment_file and logistics_file:
        try:
            # è¯»å–ä¸¤ä¸ªæ–‡ä»¶
            pending_shipment_df = pd.read_excel(pending_shipment_file)
            logistics_df = pd.read_excel(logistics_file)
            
            # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
            for col in pending_shipment_df.columns:
                pending_shipment_df[col] = pending_shipment_df[col].astype(str)
                
            for col in logistics_df.columns:
                logistics_df[col] = logistics_df[col].astype(str)
            
            st.subheader("å¾…å‘è´§æ˜ç»†è¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(pending_shipment_df.head(10))
            
            st.subheader("ç‰©æµå•å·è¡¨æ•°æ®é¢„è§ˆ")
            st.dataframe(logistics_df.head(10))
            
            # æ˜¾ç¤ºåˆ—å
            st.subheader("åˆ—åä¿¡æ¯")
            with st.expander("ç‚¹å‡»å±•å¼€/æ”¶èµ·åˆ—åè¯¦æƒ…"):
                col1, col2 = st.columns(2)
                with col1:
                    st.write("å¾…å‘è´§æ˜ç»†è¡¨åˆ—å:")
                    st.write(list(pending_shipment_df.columns))
                with col2:
                    st.write("ç‰©æµå•å·è¡¨åˆ—å:")
                    st.write(list(logistics_df.columns))
            
            # è‡ªåŠ¨åŒ¹é…å…³é”®åˆ—
            st.subheader("å…³é”®åˆ—åŒ¹é…")
            
            # å®šä¹‰å¯èƒ½çš„åˆ—å
            pending_shipment_name_cols = ['æ”¶è´§äºº', 'æ”¶ä»¶äºº', 'å®¢æˆ·åç§°', 'å§“å']
            logistics_name_cols = ['æ”¶ä»¶äºº', 'æ”¶è´§äºº', 'å®¢æˆ·åç§°', 'å§“å']
            
            # è‡ªåŠ¨æ£€æµ‹åŒ¹é…åˆ—ï¼Œä¼˜å…ˆé€‰æ‹©"æ”¶è´§äºº"
            pending_name_col = None
            logistics_name_col = None
            
            # ä¼˜å…ˆæ£€æŸ¥"æ”¶è´§äºº"åˆ—
            if 'æ”¶è´§äºº' in pending_shipment_df.columns:
                pending_name_col = 'æ”¶è´§äºº'
            else:
                for col in pending_shipment_df.columns:
                    if col in pending_shipment_name_cols:
                        pending_name_col = col
                        break
            
            if 'æ”¶è´§äºº' in logistics_df.columns:
                logistics_name_col = 'æ”¶è´§äºº'
            else:
                for col in logistics_df.columns:
                    if col in logistics_name_cols:
                        logistics_name_col = col
                        break
            
            # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„åˆ—
            st.write("è‡ªåŠ¨æ£€æµ‹åˆ°çš„åŒ¹é…åˆ—:")
            with st.expander("ç‚¹å‡»é€‰æ‹©åŒ¹é…åˆ—", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    pending_name_select = st.selectbox(
                        "å¾…å‘è´§æ˜ç»†è¡¨ä¸­çš„æ”¶ä»¶äººåˆ—", 
                        pending_shipment_df.columns, 
                        index=pending_shipment_df.columns.tolist().index(pending_name_col) if pending_name_col else 0,
                        key="pending_name_select"
                    )
                with col2:
                    logistics_name_select = st.selectbox(
                        "ç‰©æµå•å·è¡¨ä¸­çš„æ”¶ä»¶äººåˆ—", 
                        logistics_df.columns, 
                        index=logistics_df.columns.tolist().index(logistics_name_col) if logistics_name_col else 0,
                        key="logistics_name_select"
                    )
            
            # é€‰æ‹©è¦æ·»åŠ çš„åˆ—
            st.subheader("é€‰æ‹©è¦æ·»åŠ çš„åˆ—")
            available_columns = [col for col in logistics_df.columns if col not in [logistics_name_select]]
            
            # è®¾ç½®é»˜è®¤é€‰ä¸­çš„åˆ—
            default_columns = []
            common_logistics_columns = ['ç‰©æµå…¬å¸', 'ç‰©æµå•å·', 'é¢å¤–ç‰©æµå•å·']
            for col in common_logistics_columns:
                if col in available_columns:
                    default_columns.append(col)
            
            with st.expander("ç‚¹å‡»é€‰æ‹©è¦æ·»åŠ çš„åˆ—", expanded=True):
                columns_to_add = st.multiselect(
                    "é€‰æ‹©è¦ä»ç‰©æµå•å·è¡¨æ·»åŠ åˆ°å¾…å‘è´§æ˜ç»†è¡¨çš„åˆ—",
                    available_columns,
                    default=default_columns,
                    key="columns_to_add"
                )
                st.write("å·²é€‰æ‹©è¦æ·»åŠ çš„åˆ—:", columns_to_add)
            
            # å¤„ç†é‡å¤é¡¹é€‰é¡¹
            st.subheader("é‡å¤é¡¹å¤„ç†")
            handle_duplicates = st.radio(
                "å¦‚ä½•å¤„ç†ç‰©æµå•å·è¡¨ä¸­çš„é‡å¤æ”¶ä»¶äººè®°å½•",
                ["ä¿ç•™ç¬¬ä¸€æ¡è®°å½•", "åˆå¹¶æ‰€æœ‰è®°å½•ï¼ˆå¯èƒ½å¯¼è‡´è¡Œæ•°å¢åŠ ï¼‰"],
                index=0,
                key="handle_duplicates"
            )
            
            # é€‰æ‹©è¾“å‡ºåˆ—
            st.subheader("è¾“å‡ºåˆ—é€‰æ‹©")
            with st.expander("ç‚¹å‡»é€‰æ‹©è¾“å‡ºåˆ—", expanded=True):
                # å®šä¹‰å…³é”®åˆ—
                key_columns = ['ç½‘åº—è®¢å•å·', 'æ”¶è´§äºº', 'æ‰‹æœº', 'æ”¶è´§åœ°å€', 'è´§å“åç§°', 'è§„æ ¼', 'æ•°é‡', 'ç‰©æµå…¬å¸', 'ç‰©æµå•å·', 'é¢å¤–ç‰©æµå•å·', 'å‘è´§æ—¶é—´']
                
                # åˆå¹¶åçš„æ‰€æœ‰å¯èƒ½åˆ—
                all_possible_columns = list(pending_shipment_df.columns) + columns_to_add
                
                # ç¡®ä¿å…³é”®åˆ—ä¼˜å…ˆæ˜¾ç¤º
                ordered_columns = []
                # å…ˆæ·»åŠ å…³é”®åˆ—ä¸­å­˜åœ¨äºæ•°æ®ä¸­çš„åˆ—
                for col in key_columns:
                    if col in all_possible_columns and col not in ordered_columns:
                        ordered_columns.append(col)
                
                # å†æ·»åŠ å…¶ä»–åˆ—
                for col in all_possible_columns:
                    if col not in ordered_columns:
                        ordered_columns.append(col)
                
                # é»˜è®¤é€‰ä¸­æ‰€æœ‰å…³é”®åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰åŠ ä¸Šä»ç‰©æµè¡¨æ·»åŠ çš„åˆ—
                default_output_columns = []
                for col in key_columns:
                    if col in all_possible_columns:
                        default_output_columns.append(col)
                
                # æ·»åŠ ä»ç‰©æµå•å·è¡¨ä¸­é€‰æ‹©çš„åˆ—ï¼ˆå¦‚æœå°šæœªåŒ…å«ï¼‰
                for col in columns_to_add:
                    if col not in default_output_columns:
                        default_output_columns.append(col)
                
                output_columns = st.multiselect(
                    "é€‰æ‹©æœ€ç»ˆè¾“å‡ºçš„åˆ—ï¼ˆå¯è‡ªå®šä¹‰ï¼‰",
                    ordered_columns,
                    default=default_output_columns,
                    key="output_columns"
                )
            
            if st.button("æ‰§è¡ŒåŒ¹é…"):
                if columns_to_add:
                    with st.spinner("æ­£åœ¨æ‰§è¡ŒåŒ¹é…..."):
                        try:
                            # å¤„ç†ç‰©æµå•å·è¡¨ä¸­çš„é‡å¤è®°å½•
                            if handle_duplicates == "ä¿ç•™ç¬¬ä¸€æ¡è®°å½•":
                                # å¯¹äºæ¯ä¸ªæ”¶ä»¶äººï¼Œåªä¿ç•™ç¬¬ä¸€æ¡è®°å½•
                                logistics_df_unique = logistics_df.drop_duplicates(subset=[logistics_name_select], keep='first')
                            else:
                                logistics_df_unique = logistics_df
                            
                            # ä¸ºäº†é¿å…é‡å¤åˆ—åï¼Œæˆ‘ä»¬å…ˆä»ä¸»è¡¨ä¸­ç§»é™¤ä¸ç‰©æµè¡¨åŒåçš„åˆ—ï¼ˆé™¤äº†åŒ¹é…é”®ï¼‰
                            pending_shipment_for_merge = pending_shipment_df.copy()
                            columns_to_drop = []
                            for col in columns_to_add:
                                if col in pending_shipment_for_merge.columns:
                                    columns_to_drop.append(col)
                            
                            if columns_to_drop:
                                pending_shipment_for_merge = pending_shipment_for_merge.drop(columns=columns_to_drop)
                            
                            # ä½¿ç”¨æ”¶ä»¶äººä½œä¸ºåŒ¹é…é”®
                            merge_columns = [logistics_name_select] + columns_to_add
                            
                            result_df = pd.merge(
                                pending_shipment_for_merge,
                                logistics_df_unique[merge_columns],
                                left_on=pending_name_select,
                                right_on=logistics_name_select,
                                how='left',
                                sort=False
                            )
                            
                            # ç¡®ä¿ç»“æœDataFrameçš„æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                            for col in result_df.columns:
                                result_df[col] = result_df[col].astype(str)
                            
                            # æ˜¾ç¤ºåŒ¹é…ç»Ÿè®¡ä¿¡æ¯
                            matched_count = 0
                            if columns_to_add:
                                # æ£€æŸ¥ç¬¬ä¸€åˆ—æ˜¯å¦å­˜åœ¨äºç»“æœä¸­
                                first_column = columns_to_add[0]
                                if first_column in result_df.columns:
                                    matched_count = result_df[first_column].notna().sum()
                                else:
                                    # å¦‚æœç¬¬ä¸€åˆ—ä¸å­˜åœ¨ï¼Œæ£€æŸ¥å…¶ä»–åˆ—
                                    for col in columns_to_add:
                                        if col in result_df.columns:
                                            matched_count = result_df[col].notna().sum()
                                            break
                            st.info(f"æˆåŠŸåŒ¹é… {matched_count} æ¡è®°å½•")
                            
                            # åªä¿ç•™æŒ‡å®šçš„è¾“å‡ºåˆ—
                            if output_columns:
                                # æ£€æŸ¥é€‰å®šçš„åˆ—æ˜¯å¦å­˜åœ¨äºç»“æœä¸­
                                existing_output_columns = [col for col in output_columns if col in result_df.columns]
                                result_df = result_df[existing_output_columns]
                            
                            st.success("åŒ¹é…å®Œæˆï¼")
                            st.subheader("åŒ¹é…ç»“æœç»Ÿè®¡")
                            st.write(f"åŸå§‹å¾…å‘è´§æ˜ç»†è¡¨è¡Œæ•°: {len(pending_shipment_df)}")
                            st.write(f"åŒ¹é…åç»“æœè¡Œæ•°: {len(result_df)}")
                            
                            if len(result_df) > len(pending_shipment_df):
                                st.warning("æ³¨æ„ï¼šç»“æœè¡Œæ•°å¢åŠ ï¼Œè¿™æ˜¯å› ä¸ºæŸäº›æ”¶ä»¶äººåœ¨ç‰©æµå•å·è¡¨ä¸­æœ‰å¤šæ¡è®°å½•")
                            
                            st.subheader("åŒ¹é…ç»“æœé¢„è§ˆ")
                            st.dataframe(result_df.head(20))
                            
                            # æä¾›ä¸‹è½½
                            output_file = f"å‘è´§æ˜ç»†_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                            result_df.to_excel(output_file, index=False)
                            
                            with open(output_file, "rb") as file:
                                st.download_button(
                                    label="ä¸‹è½½åŒ¹é…ç»“æœ",
                                    data=file,
                                    file_name=output_file,
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        except Exception as e:
                            st.error(f"åŒ¹é…è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                            import traceback
                            st.error(traceback.format_exc())
                else:
                    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€åˆ—æ·»åŠ åˆ°å¾…å‘è´§æ˜ç»†è¡¨ä¸­")
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            st.error(traceback.format_exc())

elif app_mode == "è¡¨åˆå¹¶":
    st.header("è¡¨åˆå¹¶")
    st.info("æ­¤åŠŸèƒ½å°†çºµå‘åˆå¹¶å¤šä¸ªè¡¨æ ¼ï¼Œå¹¶è‡ªåŠ¨ç§»é™¤å…¨ç©ºçš„åˆ—")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ éœ€è¦åˆå¹¶çš„Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
        type=["xlsx"],
        accept_multiple_files=True,
        key="merge_files"
    )
    
    if uploaded_files and len(uploaded_files) >= 2:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        if st.button("æ‰§è¡Œåˆå¹¶"):
            with st.spinner("æ­£åœ¨æ‰§è¡Œåˆå¹¶..."):
                try:
                    # è¯»å–æ‰€æœ‰æ–‡ä»¶
                    dataframes = []
                    for uploaded_file in uploaded_files:
                        df = pd.read_excel(uploaded_file)
                        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
                        for col in df.columns:
                            df[col] = df[col].astype(str)
                        dataframes.append(df)
                    
                    # çºµå‘åˆå¹¶æ‰€æœ‰è¡¨æ ¼
                    result_df = pd.concat(dataframes, ignore_index=True)
                    
                    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    for col in result_df.columns:
                        result_df[col] = result_df[col].astype(str)
                    
                    # è‡ªåŠ¨è¿‡æ»¤å…¨ç©ºçš„åˆ—
                    columns_to_keep = []
                    for col in result_df.columns:
                        # æ£€æŸ¥åˆ—æ˜¯å¦å…¨ä¸ºç©ºå€¼ï¼ˆé™¤äº†æ ‡é¢˜ï¼‰
                        non_empty_values = result_df[col][result_df[col].notna() & (result_df[col] != '') & (result_df[col] != 'nan')]
                        if len(non_empty_values) > 0:
                            columns_to_keep.append(col)
                    
                    # åªä¿ç•™éç©ºåˆ—
                    result_df = result_df[columns_to_keep]
                    
                    st.success("åˆå¹¶å®Œæˆï¼")
                    st.write(f"åˆå¹¶åæ€»è¡Œæ•°: {len(result_df)}ï¼Œæ€»åˆ—æ•°: {len(result_df.columns)}")
                    
                    st.subheader("åˆå¹¶ç»“æœé¢„è§ˆ")
                    st.dataframe(result_df.head(20))
                    
                    # æä¾›ä¸‹è½½
                    output_file = f"åˆå¹¶ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                    result_df.to_excel(output_file, index=False)
                    
                    with open(output_file, "rb") as file:
                        st.download_button(
                            label="ä¸‹è½½åˆå¹¶ç»“æœ",
                            data=file,
                            file_name=output_file,
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                        )
                except Exception as e:
                    st.error(f"åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                    import traceback
                    st.error(traceback.format_exc())
    else:
        st.info("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶è¿›è¡Œåˆå¹¶")

elif app_mode == "ç®€åŒ–è¡¨åˆå¹¶":
    st.header("ç®€åŒ–è¡¨åˆå¹¶")
    st.info("æ­¤åŠŸèƒ½å°†çºµå‘åˆå¹¶å¤šä¸ªè¡¨æ ¼ï¼Œå¹¶è‡ªåŠ¨ç§»é™¤å…¨ç©ºçš„åˆ—")
    
    # æ–‡ä»¶ä¸Šä¼ 
    uploaded_files = st.file_uploader(
        "ä¸Šä¼ éœ€è¦åˆå¹¶çš„Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šä¸ªæ–‡ä»¶ï¼‰",
        type=["xlsx"],
        accept_multiple_files=True,
        key="simple_merge_files"
    )
    
    if uploaded_files and len(uploaded_files) >= 2:
        st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
        
        # æ˜¾ç¤ºä¸Šä¼ çš„æ–‡ä»¶å
        file_names = [f.name for f in uploaded_files]
        st.write("ä¸Šä¼ çš„æ–‡ä»¶:")
        for i, name in enumerate(file_names):
            st.write(f"{i+1}. {name}")
        
        try:
            # è¯»å–æ‰€æœ‰æ–‡ä»¶
            dataframes = []
            for uploaded_file in uploaded_files:
                df = pd.read_excel(uploaded_file)
                # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…PyArrowé”™è¯¯
                for col in df.columns:
                    df[col] = df[col].astype(str)
                dataframes.append(df)
            
            st.subheader("æ–‡ä»¶é¢„è§ˆ")
            tabs = st.tabs([f"è¡¨{i+1}" for i in range(len(dataframes))])
            for i, (tab, df) in enumerate(zip(tabs, dataframes)):
                with tab:
                    st.write(f"è¡¨{i+1} ({file_names[i]}) åˆ—å:")
                    st.write(list(df.columns))
                    st.write(f"å‰5è¡Œæ•°æ®:")
                    st.dataframe(df.head(5))
            
            if st.button("æ‰§è¡Œåˆå¹¶"):
                with st.spinner("æ­£åœ¨æ‰§è¡Œåˆå¹¶..."):
                    try:
                        # çºµå‘åˆå¹¶æ‰€æœ‰è¡¨æ ¼
                        result_df = pd.concat(dataframes, ignore_index=True)
                        
                        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
                        for col in result_df.columns:
                            result_df[col] = result_df[col].astype(str)
                        
                        st.write(f"åˆå¹¶åæ€»è¡Œæ•°: {len(result_df)}")
                        
                        # æ˜¾ç¤ºæ‰€æœ‰åˆ—å
                        st.write("æ‰€æœ‰åˆ—å:")
                        all_columns = list(result_df.columns)
                        st.write(all_columns)
                        
                        # è‡ªåŠ¨è¿‡æ»¤å…¨ç©ºçš„åˆ—
                        columns_to_keep = []
                        for col in result_df.columns:
                            # æ£€æŸ¥åˆ—æ˜¯å¦å…¨ä¸ºç©ºå€¼ï¼ˆé™¤äº†æ ‡é¢˜ï¼‰
                            non_empty_values = result_df[col][result_df[col].notna() & (result_df[col] != '') & (result_df[col] != 'nan')]
                            if len(non_empty_values) > 0:
                                columns_to_keep.append(col)
                        
                        st.write("éç©ºåˆ—:")
                        st.write(columns_to_keep)
                        
                        # é€‰æ‹©è¦ä¿ç•™çš„åˆ—
                        st.subheader("é€‰æ‹©è¦ä¿ç•™çš„åˆ—")
                        selected_columns = st.multiselect(
                            "é€‰æ‹©è¦ä¿ç•™çš„åˆ—ï¼ˆé»˜è®¤é€‰æ‹©æ‰€æœ‰éç©ºåˆ—ï¼‰",
                            all_columns,
                            default=columns_to_keep,
                            key="selected_columns"
                        )
                        
                        # å¦‚æœç”¨æˆ·é€‰æ‹©äº†åˆ—ï¼Œåˆ™åªä¿ç•™è¿™äº›åˆ—
                        if selected_columns:
                            result_df = result_df[selected_columns]
                        
                        st.success("åˆå¹¶å®Œæˆï¼")
                        st.subheader("åˆå¹¶ç»“æœç»Ÿè®¡")
                        st.write(f"åˆå¹¶åæ€»è¡Œæ•°: {len(result_df)}")
                        st.write(f"åˆå¹¶åæ€»åˆ—æ•°: {len(result_df.columns)}")
                        
                        st.subheader("åˆå¹¶ç»“æœé¢„è§ˆ")
                        st.dataframe(result_df.head(20))
                        
                        # æä¾›ä¸‹è½½
                        output_file = f"ç®€åŒ–åˆå¹¶ç»“æœ_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx"
                        result_df.to_excel(output_file, index=False)
                        
                        with open(output_file, "rb") as file:
                            st.download_button(
                                label="ä¸‹è½½åˆå¹¶ç»“æœ",
                                data=file,
                                file_name=output_file,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                            )
                    except Exception as e:
                        st.error(f"åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
                        import traceback
                        st.error(traceback.format_exc())
        except Exception as e:
            st.error(f"æ–‡ä»¶è¯»å–æˆ–å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            import traceback
            st.error(traceback.format_exc())
    else:
        st.info("è¯·è‡³å°‘ä¸Šä¼ ä¸¤ä¸ªExcelæ–‡ä»¶è¿›è¡Œåˆå¹¶")

# é¡µè„š
st.markdown("---")
st.markdown("Â© 2025 æ•°æ®å¤„ç†ç³»ç»Ÿ v1.0")